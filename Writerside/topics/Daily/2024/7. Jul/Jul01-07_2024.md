# July 2024, Week 1: July 1st - July 7th

## July 1 -> 1550. Three Consecutive Odds {collapsible="true" default-state="collapsed"}

Given an integer `arr`, return `true` if there are three consecutive odd numbers in the array.
Otherwise, return `false`.

**Example 1:**

**Input:** arr = [2,6,4,1]
**Output:** false
**Explanation:** There are no three consecutive odds.

**Example 2:**

**Input:** arr = [1,2,34,3,4,5,7,23,12]
**Output:** true
**Explanation:** [5,7,23] are three consecutive odds.

**Constraints:**

- `1 <= arr.length <= 1000`
- `1 <= arr[i] <= 1000`

---

### Approach 1: Single-Pass Counter {id="approach_d1_1" collapsible="true" default-state="expanded"}

```Python
def threeConsecutiveOdds1(arr: List[int]) -> bool:
    """
    Determines if there are three consecutive odd numbers in the given array.

    This function iterates through the array once, keeping track of the count
    of consecutive odd numbers encountered. It uses a single variable
    'consecutive_odds' to maintain this count, resetting it to 0 whenever an
    even number is found. This approach is memory-efficient and allows for a
    single-pass solution.

    The time complexity of this solution is O(n), where `n` is the length of
    the input array, because it performs a single iteration through the array
    in the worst case. The space complexity is O(1) as it uses only a
    constant amount of extra space regardless of the input size.
    """
    if len(arr) < 3:
        return False
    
    consecutive_odds = 0
    for num in arr:
        if num % 2:
            consecutive_odds += 1
        else:
            consecutive_odds = 0
        if consecutive_odds == 3:
            return True
    return False
```

{collapsible="true" default-state="expanded" collapsed-title="Single-Pass Counter Code..."}

#### Understanding the Core Idea {id="core-idea_d1_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage a single-pass iteration with a counter to efficiently detect three
consecutive odd numbers in the array.
This approach exploits the sequential nature of the problem and the binary property of numbers (odd or even).

- **Counter Reset Mechanism:** The solution uses a counter that increments for odd numbers and resets for even numbers,
  allowing it to track consecutive odd numbers efficiently.
- **Early Termination:** The algorithm returns `True` as soon as it detects three consecutive odd numbers, avoiding
  unnecessary iterations through the rest of the array.

> **Key Insight:**
> By using a single counter and resetting it when an even number is encountered, the algorithm can
> detect three consecutive odd numbers without needing to store or track individual numbers, leading to constant space
> complexity.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d1_1" collapsible="true" default-state="expanded"}

1. **Input Validation:**
   ```python
   if len(arr) < 3:
       return False
   ```
   This check ensures that the array has at least three elements.
   If not, it's impossible to have three consecutive odd numbers, so we return `False` immediately.
   This optimization prevents unnecessary processing for small arrays.

2. **Counter Initialization:**
   ```python
   consecutive_odds = 0
   ```
   We initialize a counter `consecutive_odds` to keep track of the number of consecutive odd integers encountered.
   This single variable is key to the algorithm's space efficiency.

3. **Array Iteration and Odd Number Detection:**
   ```python
   for num in arr:
       if num % 2:
           consecutive_odds += 1
       else:
           consecutive_odds = 0
   ```
   We iterate through each number in the array.
   The modulo operation `num % 2` checks if a number is odd (remainder 1 when divided by 2).
   If it's odd, we increment the counter.
   If it's even, we reset the counter to 0.
   This reset is crucial as it ensures we're only counting consecutive odd numbers.

4. **Consecutive Odd Check and Early Return:**
   ```python
   if consecutive_odds == 3:
       return True
   ```
   After each update to `consecutive_odds`, we check if it has reached 3. If so, we've found three consecutive odd
   numbers, and we can immediately return `True`.
   This early return optimizes the function by avoiding unnecessary iterations once the condition is met.

5. **Final Return:**
   ```python
   return False
   ```
   If we've iterated through the entire array without finding three consecutive odd numbers, we return `False`.

---

#### Complexity Analysis {id="complexity-analysis_d1_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the length of the input array `arr`.
  This is because in the worst case, we need to iterate through all elements of the array once.
  Each operation inside the loop (modulo, increment, comparison) takes constant
  time, so the overall time complexity is linear with respect to the array length.

**Space Complexity:**

- $O(1)$, or constant space.
  This is because we only use a single integer variable `consecutive_odds` regardless of the input size.
  The space used does not grow with the size of the input array, making this solution very memory-efficient.

---

#### Example {id="example_d1_1" collapsible="true" default-state="expanded"}

**Input:**

```python
arr = [1, 2, 34, 3, 4, 5, 7, 23, 12]
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - The function `threeConsecutiveOdds1` is called with the input array `[1, 2, 34, 3, 4, 5, 7, 23, 12]`.
    - The variable `consecutive_odds` is initialized to 0.
      This variable will keep track of the count of consecutive odd numbers encountered.

2. **Input Validation:**
    - The function checks if the length of the input array is less than 3.
    - In this case, the array length is 9, which is valid (greater than or equal to 3), so the function proceeds.

3. **Main Loop:**

    - **Iteration 1:**
        - Current number: 1
        - 1 is odd (1 % 2 = 1), so `consecutive_odds` is incremented to 1.
        - 1 < 3, so the function continues to the next iteration.

    - **Iteration 2:**
        - Current number: 2
        - 2 is even (2 % 2 = 0), so `consecutive_odds` is reset to 0.

    - **Iteration 3:**
        - Current number: 34
        - 34 is even (34 % 2 = 0), so `consecutive_odds` remains 0.

    - **Iteration 4:**
        - Current number: 3
        - 3 is odd (3 % 2 = 1), so `consecutive_odds` is incremented to 1.

    - **Iteration 5:**
        - Current number: 4
        - 4 is even (4 % 2 = 0), so `consecutive_odds` is reset to 0.

    - **Iteration 6:**
        - Current number: 5
        - 5 is odd (5 % 2 = 1), so `consecutive_odds` is incremented to 1.

    - **Iteration 7:**
        - Current number: 7
        - 7 is odd (7 % 2 = 1), so `consecutive_odds` is incremented to 2.

    - **Iteration 8:**
        - Current number: 23
        - 23 is odd (23 % 2 = 1), so `consecutive_odds` is incremented to 3.
        - At this point, `consecutive_odds` equals 3, so the function immediately returns `True`.

4. **Visual Aid:**
    - The iteration summary table shows the progression of the `consecutive_odds` count for each element in the array.
        
    | Element | Number | Odd/Even | Consecutive Odds |
    |---------|--------|----------|------------------|
    | 1       | 1      | Odd      | 1                |
    | 2       | 2      | Even     | 0                |
    | 3       | 34     | Even     | 0                |
    | 4       | 3      | Odd      | 1                |
    | 5       | 4      | Even     | 0                |
    | 6       | 5      | Odd      | 1                |
    | 7       | 7      | Odd      | 2                |
    | 8       | 23     | Odd      | 3                |

5. **Result Calculation/Final Steps:**
    - The function returns `True` as soon as it encounters three consecutive odd numbers (5, 7, 23).
    - The last element (12) is not processed because the function has already found the desired pattern and returned.

---

## July 2 -> 350. Intersection of Two Arrays II {collapsible="true" default-state="collapsed"}

Given two integer arrays `nums1` and `nums2`, return *an array of their intersection*.
Each element in the result must appear as many times as it shows in both arrays,
and you may return the result in **any order**.

**Example 1:**

- **Input:** nums1 = [1,2,2,1], nums2 = [2,2]
- **Output:** [2,2]

**Example 2:**

- **Input:** nums1 = [4,9,5], nums2 = [9,4,9,8,4]
- **Output:** [4,9]
- **Explanation:** [9,4] is also accepted.

**Constraints:**

- `1 <= nums1.length, nums2.length <= 1000`
- `0 <= nums1[i], nums2[i] <= 1000`

---

### Approach 1: Two-Pointer on Sorted Arrays {id="approach_d2_1" collapsible="true" default-state="expanded"}

```Python
def intersect1(nums1: List[int], nums2: List[int]) -> List[int]:
    """
    Finds the intersection of two integer arrays, maintaining element
    frequency.

    This function uses a two-pointer approach on sorted arrays to
    efficiently find the intersection. By sorting both arrays first, we can
    compare elements linearly, adding common elements to the result. The
    algorithm ensures that each element appears in the result as many times
    as it appears in both input arrays. Swapping arrays if `nums1` is longer
    optimizes for space efficiency.

    The time complexity is O(n log n + m log m) for sorting, where `n` and
    `m` are the lengths of `nums1` and `nums2` respectively. The sorting step
    dominates the overall time complexity, as the two-pointer traversal is
    linear. The space complexity is O(min(n, m)) for the result array,
    excluding the space used for sorting (which could be O(n) for python's
    built-in sort).
    """
    # Ensure nums1 is the shorter array for efficiency
    if len(nums1) > len(nums2):
        nums1, nums2 = nums2, nums1

    nums1.sort()
    nums2.sort()

    intersection = []
    index1, index2 = 0, 0

    while index1 < len(nums1) and index2 < len(nums2):
        if nums1[index1] < nums2[index2]:
            index1 += 1
        elif nums1[index1] > nums2[index2]:
            index2 += 1
        else:
            intersection.append(nums1[index1])
            index1 += 1
            index2 += 1

    return intersection
```

{collapsible="true" default-state="expanded" collapsed-title="Two-Pointer on Sorted Arrays Code..."}

#### Understanding the Core Idea {id="core-idea_d2_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage sorted arrays and a two-pointer technique to efficiently find the
intersection of two integer arrays while maintaining element frequency.
This approach exploits the ordered nature of sorted arrays to compare elements linearly and identify common elements.

- **Sorting**: By sorting both input arrays, we create a structure where identical elements are grouped together, making
  comparisons easier.
- **Two-Pointer Technique**: Using two pointers, one for each sorted array, we can traverse both arrays simultaneously,
  comparing elements and identifying matches.
- **Frequency Preservation**: The algorithm naturally preserves the frequency of elements in the intersection by
  including a match in the result each time it occurs in both arrays.

> **Key Insight**:
> Swapping the arrays if `nums1` is longer than `nums2` optimizes space efficiency by ensuring we work
> with the shorter array first, potentially reducing the size of the result array.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d2_1" collapsible="true" default-state="expanded"}

1. **Array Swapping for Optimization:**
   ```python
   if len(nums1) > len(nums2):
       nums1, nums2 = nums2, nums1
   ```
   This step ensures that `nums1` is always the shorter (or equal length) array.
   This optimization can reduce space complexity in cases where one array is significantly shorter than the other.

2. **Sorting the Arrays:**
   ```python
   nums1.sort()
   nums2.sort()
   ```
   Sorting both arrays is crucial for the two-pointer approach to work.
   It allows us to compare elements sequentially and efficiently identify matches.

3. **Initialization:**
   ```python
   intersection = []
   index1, index2 = 0, 0
   ```
   We initialize an empty list `intersection` to store the result, and two pointers `index1` and `index2` to
   traverse `nums1` and `nums2` respectively.

4. **Two-Pointer Traversal:**
   ```python
   while index1 < len(nums1) and index2 < len(nums2):
       if nums1[index1] < nums2[index2]:
           index1 += 1
       elif nums1[index1] > nums2[index2]:
           index2 += 1
       else:
           intersection.append(nums1[index1])
           index1 += 1
           index2 += 1
   ```
   This is the core of the algorithm. We compare elements from both arrays:
    - If the element in `nums1` is smaller, we move the `index1` pointer.
    - If the element in `nums2` is smaller, we move the `index2` pointer.
    - If they are equal, we've found an intersection element.
      We add it to the result and move both pointers.
      This process naturally handles frequency, as we only add an element when we find a match in both arrays.

5. **Result Return:**
   ```python
   return intersection
   ```
   After the traversal, `intersection` contains all common elements with their correct frequencies, so we return it.

---

#### Complexity Analysis {id="complexity-analysis_d2_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n \log n + m \log m)$, where $n$ and $m$ are the lengths of `nums1` and `nums2` respectively. This is because:
    1. Sorting both arrays takes $O(n \log n)$ and $O(m \log m)$ time.
    2. The two-pointer traversal is linear, $O(n + m)$.
    3. The sorting step dominates the time complexity.

**Space Complexity:**

- $O(\min(n, m))$, where $n$ and $m$ are the lengths of `nums1` and `nums2`. This is because:
    1. The result array `intersection` will at most contain as many elements as the shorter input array.
    2. The space used for sorting (which could be $O(n)$ or $O(m)$ for Python's built-in sort) is not counted as extra
       space in this analysis, as it's considered part of the input modification.
    3. Apart from the result array, we only use a constant amount of extra space for pointers and temporary variables.

---

#### Example {id="example_d2_1" collapsible="true" default-state="expanded"}

**Input:**

```python
nums1 = [4, 9, 5]
nums2 = [9, 4, 9, 8, 4]
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - The function first checks if `nums1` is longer than `nums2`. In this case, `len(nums1) = 3` and `len(nums2) = 5`,
      so no swap occurs.
    - Both arrays are then sorted:
        - `nums1` becomes `[4, 5, 9]`
        - `nums2` becomes `[4, 4, 8, 9, 9]`
    - Initialize `intersection = []`, `index1 = 0`, and `index2 = 0`

2. **Main Loop (Two-pointer comparison):**

    - **Iteration 1:**
        - Compare `nums1[0] = 4` and `nums2[0] = 4`
        - They are equal, so add 4 to `intersection`
        - Increment both `index1` and `index2`
        - Current state: `intersection = [4]`, `index1 = 1`, `index2 = 1`

    - **Iteration 2:**
        - Compare `nums1[1] = 5` and `nums2[1] = 4`
        - `5 > 4`, so increment only `index2`
        - Current state: `intersection = [4]`, `index1 = 1`, `index2 = 2`

    - **Iteration 3:**
        - Compare `nums1[1] = 5` and `nums2[2] = 8`
        - `5 < 8`, so increment only `index1`
        - Current state: `intersection = [4]`, `index1 = 2`, `index2 = 2`

    - **Iteration 4:**
        - Compare `nums1[2] = 9` and `nums2[2] = 8`
        - `9 > 8`, so increment only `index2`
        - Current state: `intersection = [4]`, `index1 = 2`, `index2 = 3`

    - **Iteration 5:**
        - Compare `nums1[2] = 9` and `nums2[3] = 9`
        - They are equal, so add 9 to `intersection`
        - Increment both `index1` and `index2`
        - Current state: `intersection = [4, 9]`, `index1 = 3`, `index2 = 4`

3. **Loop Termination:**
    - After iteration 5, `index1 = 3`, which equals `len(nums1)`, so the loop terminates
    - The final state of variables:
        - `intersection = [4, 9]`
        - `index1 = 3`
        - `index2 = 4`

4. **Visual Aid:**

   Iteration Summary Table:

   | Iteration | index1 | index2 | nums1 value | nums2 value | Action                              | Current Intersection |
   |-----------|--------|--------|-------------|-------------|-------------------------------------|----------------------|
   | 1         | 0      | 0      | 4           | 4           | Add to intersection, increment both | [4]                  |
   | 2         | 1      | 1      | 5           | 4           | Increment index2                    | [4]                  |
   | 3         | 1      | 2      | 5           | 8           | Increment index1                    | [4]                  |
   | 4         | 2      | 2      | 9           | 8           | Increment index2                    | [4]                  |
   | 5         | 2      | 3      | 9           | 9           | Add to intersection, increment both | [4, 9]               |

5. **Result Calculation/Final Steps:**
    - The algorithm has already built the intersection array during the loop iterations
    - No further calculations are needed
    - The function returns the final `intersection` array: `[4, 9]`

---

### Approach 2: Hash Table (Counter) Approach {id="approach_d2_2" collapsible="true" default-state="expanded"}

```Python
def intersect2(nums1: List[int], nums2: List[int]) -> List[int]:
    """
    Finds the intersection of two integer arrays, maintaining element
    frequency.

    This function uses a hash table approach using Python's Counter class. It
    first ensures that `nums1` is the shorter array to optimize space usage.
    Then, it creates a frequency map of `nums1` and iterates through `nums2`,
    adding common elements to the result while decrementing their count in
    the frequency map. This method efficiently handles unsorted input and can 
    terminate early if all elements from the shorter array are found.

    The time complexity is O(n + m), where `n` and `m` are the lengths of
    `nums1` and `nums2` respectively. This is because we iterate through
    `nums1` once to build the Counter and then through `nums2` to find the
    intersection. The space complexity is O(min(n, m)) for the Counter and
    the result list, as we ensure `nums1` is the shorter array.
    """
    # Ensure nums1 is the shorter array for efficiency
    if len(nums1) > len(nums2):
        nums1, nums2 = nums2, nums1

    count_nums1 = Counter(nums1)

    intersection = []
    for num in nums2:
        if count_nums1[num] > 0:
            intersection.append(num)
            count_nums1[num] -= 1

    return intersection
```

{collapsible="true" default-state="expanded" collapsed-title="Hash Table (Counter) Approach Code..."}

#### Understanding the Core Idea {id="core-idea_d2_2" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage a hash table (specifically, Python's `Counter` class) to efficiently
find the intersection of two integer arrays while maintaining element frequency.
This approach exploits the $O(1)$ average-case lookup time of hash tables to quickly identify common elements.

- **Hash Table Usage**: By creating a frequency map of the shorter array, we can quickly check for the presence of
  elements and their remaining counts.
- **Single Pass through Longer Array**: We only need to iterate through the longer array once, checking each element
  against the frequency map.
- **Frequency Preservation**: The algorithm naturally preserves the frequency of elements in the intersection by
  decrementing the count in the frequency map each time a match is found.

> **Key Insight**:
> Swapping the arrays if `nums1` is longer than `nums2` optimizes space efficiency by ensuring we
> create the frequency map for the shorter array, potentially reducing memory usage significantly.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d2_2" collapsible="true" default-state="expanded"}

1. **Array Swapping for Optimization:**
   ```python
   if len(nums1) > len(nums2):
       nums1, nums2 = nums2, nums1
   ```
   This step ensures that `nums1` is always the shorter (or equal length) array.
   This optimization reduces space complexity by creating the frequency map for the smaller array.

2. **Creating the Frequency Map:**
   ```python
   count_nums1 = Counter(nums1)
   ```
   We use Python's `Counter` class to create a frequency map of `nums1`.
   This hash-based data structure allows for $O(1)$ average-case lookups and updates.

3. **Initialization of Result Array:**
   ```python
   intersection = []
   ```
   We initialize an empty list `intersection` to store the common elements.

4. **Iterating through the Longer Array:**
   ```python
   for num in nums2:
       if count_nums1[num] > 0:
           intersection.append(num)
           count_nums1[num] -= 1
   ```
   This is the core of the algorithm. For each number in `nums2`:
    - We check if it exists in `count_nums1` and has a count greater than 0.
    - If it does, we add it to the `intersection` list and decrement its count in `count_nums1`.
      This process naturally handles frequency, as we only add an element when it's still available in the frequency
      map.

5. **Result Return:**
   ```python
   return intersection
   ```
   After the iteration, `intersection` contains all common elements with their correct frequencies, so we return it.

---

#### Complexity Analysis {id="complexity-analysis_d2_2" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n + m)$, where $n$ and $m$ are the lengths of `nums1` and `nums2` respectively. This is because:
    1. Creating the `Counter` for `nums1` takes $O(n)$ time.
    2. Iterating through `nums2` takes $O(m)$ time.
    3. Each lookup and update in the `Counter` is $O(1)$ on average.

**Space Complexity:**

- $O(\min(n, m))$, where $n$ and $m$ are the lengths of `nums1` and `nums2`. This is because:
    1. The `Counter` will contain at most as many elements as the shorter input array (which we ensure is `nums1`).
    2. The result array `intersection` will also contain at most as many elements as the shorter input array.
    3. By swapping arrays if necessary, we guarantee that we're using the minimum possible space for the `Counter`.

---

#### Example {id="example_d2_2" collapsible="true" default-state="expanded"}

**Input:**

```python
nums1 = [4, 9, 5]
nums2 = [9, 4, 9, 8, 4]
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - The function first checks if `nums1` is longer than `nums2`. In this case, `len(nums1) = 3` and `len(nums2) = 5`,
      so no swap occurs.
    - Create a Counter object `count_nums1` from `nums1`:
      ```python
      count_nums1 = Counter({4: 1, 9: 1, 5: 1})
      ```
    - Initialize `intersection = []`

2. **Main Loop (Iterating through nums2):**

    - **Iteration 1:**
        - Processing `num = 9`
        - `count_nums1[9] = 1`, which is > 0
        - Add 9 to `intersection`
        - Decrement `count_nums1[9]` to 0
        - Current state: `intersection = [9]`

    - **Iteration 2:**
        - Processing `num = 4`
        - `count_nums1[4] = 1`, which is > 0
        - Add 4 to `intersection`
        - Decrement `count_nums1[4]` to 0
        - Current state: `intersection = [9, 4]`

    - **Iteration 3:**
        - Processing `num = 9`
        - `count_nums1[9] = 0`, which is not > 0
        - No action taken
        - Current state: `intersection = [9, 4]`

    - **Iteration 4:**
        - Processing `num = 8`
        - `count_nums1[8] = 0` (default for a missing key), which is not > 0
        - No action taken
        - Current state: `intersection = [9, 4]`

    - **Iteration 5:**
        - Processing `num = 4`
        - `count_nums1[4] = 0`, which is not > 0
        - No action taken
        - Current state: `intersection = [9, 4]`

3. **Loop Termination:**
    - The loop terminates after processing all elements in `nums2`
    - The final state of variables:
        - `intersection = [9, 4]`
        - `count_nums1 = Counter({4: 0, 9: 0, 5: 1})`

4. **Visual Aid:**

   Iteration Summary Table:

   | Iteration | Number | Count after action | Action                                 | Current Intersection |
   |-----------|--------|--------------------|----------------------------------------|----------------------|
   | 1         | 9      | 0                  | Add 9 to intersection, decrement count | [9]                  |
   | 2         | 4      | 0                  | Add 4 to intersection, decrement count | [9, 4]               |
   | 3         | 9      | 0                  | No action                              | [9, 4]               |
   | 4         | 8      | 0                  | No action                              | [9, 4]               |
   | 5         | 4      | 0                  | No action                              | [9, 4]               |

5. **Result Calculation/Final Steps:**
    - The algorithm has already built the intersection array during the loop iterations
    - No further calculations are needed
    - The function returns the final `intersection` array: `[9, 4]`

---

## July 3 -> 1509. Minimum Difference Between Largest and Smallest Value in Three Moves {collapsible="true" default-state="collapsed"}

You are given an integer array `nums`.

In one move, you can choose one element of `nums` and change it to **any value**.

Return *the minimum difference between the largest and smallest value
of `nums` **after performing at most three moves***.

**Example 1:**

- **Input:** nums = [5,3,2,4]
- **Output:** 0
- **Explanation:** We can make at most 3 moves.
   - In the first move, change 2 to 3. nums becomes [5,3,3,4].
   - In the second move, change 4 to 3. nums becomes [5,3,3,3].
   - In the third move, change 5 to 3. nums becomes [3,3,3,3].
   - After performing 3 moves, the difference between the minimum and maximum is 3 - 3 = 0.

**Example 2:**

- **Input:** nums = [1,5,0,10,14]
- **Output:** 1
- **Explanation:** We can make at most 3 moves.
   - In the first move, change 5 to 0. nums becomes [1,0,0,10,14].
   - In the second move, change 10 to 0. nums becomes [1,0,0,0,14].
   - In the third move, change 14 to 1. nums becomes [1,0,0,0,1].
   - After performing 3 moves, the difference between the minimum and maximum is 1 - 0 = 1.
     It can be shown that there is no way to make the difference 0 in 3 moves.

**Example 3:**

- **Input:** nums = [3,100,20]
- **Output:** 0
- **Explanation:** We can make at most 3 moves.
   - In the first move, change 100 to 7. nums becomes [3,7,20].
   - In the second move, change 20 to 7. nums becomes [3,7,7].
   - In the third move, change 3 to 7. nums becomes [7,7,7].
   - After performing three moves, the difference between the minimum and maximum is 7 - 7 = 0.

**Constraints:**

- `1 <= nums.length <= 10^5`
- `-10^9 <= nums[i] <= 10^9`

---

### Approach 1: Greedy Optimization with Heap Operations {id="approach_d3_1" collapsible="true" default-state="expanded"}

```Python
def minDifference1(nums: List[int]) -> int:
    """
    Calculates the minimum difference between the largest and smallest values
    in nums after performing at most three moves.

    This function uses a greedy approach to find the optimal solution. It
    recognizes that to minimize the difference, we should focus on changing
    either the smallest or largest elements (or a combination of both). The
    function first handles the edge case where the list has 42 or fewer
    elements. Then, it extracts the 4 smallest and 4 largest elements, as
    these are the only ones that could potentially affect the result given
    the constraint of at most three moves. It then considers all possible
    combinations of changing three elements and returns the minimum
    difference achieved.

    The time complexity of this solution is O(n log 4), which simplifies to
    O(n), where `n` is the length of nums. This is because `nsmallest` and
    `nlargest` operations take O(n log k) time, where k is 4 in this case.
    The space complexity is O(1) as we only store a constant number of
    elements (8 in total) regardless of input size.
    """
    # If we have 4 or fewer elements, we can make all elements equal
    if len(nums) <= 4:
        return 0

    smallest_four = heapq.nsmallest(4, nums)
    largest_four = heapq.nlargest(4, nums)

    # Check all possible combinations of 3 moves
    return min(
        largest_four[0] - smallest_four[3],  # Change 3 smallest
        largest_four[1] - smallest_four[2],  # Change 2 smallest, 1 largest
        largest_four[2] - smallest_four[1],  # Change 1 smallest, 2 largest
        largest_four[3] - smallest_four[0]  # Change 3 largest
    )
```

{collapsible="true" default-state="expanded" collapsed-title="Greedy Optimization with Heap Operations Code..."}

#### Understanding the Core Idea {id="core-idea_d3_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage heap operations to efficiently identify the elements that have the
most significant impact on the range of the array.
By focusing on the four smallest and four largest elements, we can
explore all possible combinations of three moves that minimize the difference between the maximum and minimum values.

- **Edge Case Handling:** The solution first addresses the scenario where the array has 4 or fewer elements, recognizing
  that in this case, all elements can be made equal.
- **Extrema Extraction:** Using heap operations, the algorithm efficiently extracts the four smallest and four largest
  elements from the array.
- **Optimal Move Combination:** By considering all possible ways to apply three moves to these extreme elements, the
  solution determines the minimal achievable difference.

> **Key Insight:** The optimal solution always involves modifying either the smallest elements, the largest elements, or
> a combination of both.
> By focusing on just the four smallest and four largest elements, we can guarantee to find the
> optimal solution without needing to consider the entire array.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d3_1" collapsible="true" default-state="expanded"}

1. **Edge Case Handling:**
   ```python
   if len(nums) <= 4:
       return 0
   ```
   This check addresses the scenario where we have four or fewer elements.
   In such cases, we can always make all elements equal using at most three moves,
   resulting in a minimum difference of 0.

2. **Extrema Extraction:**
   ```python
   smallest_four = heapq.nsmallest(4, nums)
   largest_four = heapq.nlargest(4, nums)
   ```
   Here, we use heap operations to efficiently extract the four smallest and four largest elements from the input array.
   These elements are crucial because they represent the boundaries of our possible solutions after applying up to three
   moves.

3. **Optimal Move Calculation:**
   ```python
   return min(
       largest_four[0] - smallest_four[3],  # Change 3 smallest
       largest_four[1] - smallest_four[2],  # Change 2 smallest, 1 largest
       largest_four[2] - smallest_four[1],  # Change 1 smallest, 2 largest
       largest_four[3] - smallest_four[0]   # Change 3 largest
   )
   ```
   This step calculates and compares four scenarios, each representing a different way to apply the three allowed moves:
    - Change the 3 smallest elements: We compare the largest element with the 4th smallest.
    - Change 2 smallest and 1 largest: We compare the 2nd largest with the 3rd smallest.
    - Change 1 smallest and 2 largest: We compare the 3rd largest with the 2nd smallest.
    - Change the 3 largest elements: We compare the 4th largest with the smallest element.

   By taking the minimum of these four scenarios, we find the smallest possible difference achievable with at most three
   moves.

---

#### Complexity Analysis {id="complexity-analysis_d3_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of elements in the input array `nums`.
  This is because both `heapq.nsmallest()` and `heapq.nlargest()` operations have a time complexity of $O(n \log k)$,
  where $k$ is 4 in our case.
  Since $k$ is a constant, this simplifies to $O(n)$.
  The final `min()` operation is performed on a constant number of elements, so it
  doesn't affect the overall time complexity.

**Space Complexity:**

- $O(1)$, because we only store a constant number of elements (8 in total: 4 smallest and 4 largest) regardless of the
  input size.
  The space used does not grow with the input size, making it constant space complexity.

---

#### Example {id="example_d3_1" collapsible="true" default-state="expanded"}

Input:

```python
nums = [6, 5, 0, 7, 10, 4, 8, 21]
```

Step-by-Step Walkthrough:

1. Initialization:
    - The function starts by initializing `n` as the length of the input list `nums`.
    - `n = len(nums) = 8`

2. Edge Case Check:
    - The function checks if `n <= 4`.
      In this case, `n = 8`, so this condition is false, and we proceed with the main algorithm.

3. Extracting Smallest and Largest Elements:
    - The function uses `heapq.nsmallest(4, nums)` to find the four smallest elements: `[0, 4, 5, 6]`
    - It then uses `heapq.nlargest(4, nums)` to find the four largest elements: `[21, 10, 8, 7]`
    - These operations efficiently extract the extremes without fully sorting the list.

4. Calculating Possible Differences:
    - The function calculates four different scenarios, each representing a different strategy for applying the three
      allowed moves:

    - Iteration 1 (Change 3 smallest):
        - Largest: `21` (largest element)
        - Smallest: `6` (4th smallest element)
        - Difference: `21 - 6 = 15`

    - Iteration 2 (Change 2 smallest, 1 largest):
        - Largest: `10` (2nd largest element)
        - Smallest: `5` (3rd smallest element)
        - Difference: `10 - 5 = 5`

    - Iteration 3 (Change 1 smallest, 2 largest):
        - Largest: `8` (3rd largest element)
        - Smallest: `4` (2nd smallest element)
        - Difference: `8 - 4 = 4`

    - Iteration 4 (Change 3 largest):
        - Largest: `7` (4th largest element)
        - Smallest: `0` (smallest element)
        - Difference: `7 - 0 = 7`

5. Visual Aid - Difference Summary:

   | Strategy                     | Largest | Smallest | Difference |
   |------------------------------|---------|----------|------------|
   | Change 3 smallest            | 21      | 6        | 15         |
   | Change 2 smallest, 1 largest | 10      | 5        | 5          |
   | Change 1 smallest, 2 largest | 8       | 4        | 4          |
   | Change 3 largest             | 7       | 0        | 7          |

6. Finding Minimum Difference:
    - The function identifies the minimum difference from the calculated scenarios: `4`
    - The corresponding strategy is "Change 1 smallest, 2 largest."

7. Result Calculation/Final Steps:
    - The minimum difference `4` is returned as the final result.
    - This result represents the smallest possible difference between the maximum and minimum elements in the array
      after applying at most three moves.
    - In this case, the optimal strategy would be to change the smallest element and the two largest elements, resulting
      in a final array where the difference between the largest and smallest elements is 4.

---

## July 4 -> 2181. Merge Nodes in Between Zeros {collapsible="true" default-state="collapsed"}

You are given the `head` of a linked list, which contains a series of integers **separated** by `0`'s. 
The **beginning**, and **end** of the linked list will have `Node.val == 0`.

For **every** two consecutive `0`'s, **merge** all the nodes lying in between them into a single node whose value is the
**sum** of all the merged nodes.
The modified list should not contain any `0`'s.

Return *the* `head` *of the modified linked list*.

**Example 1:**

![july07-2024-ex1.png](july07-2024-ex1.png)

- **Input:** head = [0,3,1,0,4,5,2,0]
- **Output:** [4,11]
- **Explanation:** The above figure represents the given linked list. The modified list contains
   - The sum of the nodes marked in green: 3 + 1 = 4.
   - The sum of the nodes marked in red: 4 + 5 + 2 = 11.

**Example 2:**

![july07-2024-ex2.png](july07-2024-ex2.png)

- **Input:** head = [0,1,0,3,0,2,2,0]
- **Output:** [1,3,4]
- **Explanation:** The above figure represents the given linked list. The modified list contains
   - The sum of the nodes marked in green: 1 = 1.
   - The sum of the nodes marked in red: 3 = 3.
   - The sum of the nodes marked in yellow: 2 + 2 = 4.

**Constraints:**

- The number of nodes in the list is in the range `[3, 2 * 10^5]`.
- `0 <= Node.val <= 1000`
- There are **no** two consecutive nodes with `Node.val == 0`.
- The **beginning** and **end** of the linked list have `Node.val == 0`.

---

### Approach 1: Two-Pointer Traversal with In-Place Modification {id="approach_d4_1" collapsible="true" default-state="expanded"}

```Python
def mergeNodes1(head: Optional[ListNode]) -> Optional[ListNode]:
    """
    Merges nodes between consecutive zeros in a linked list, summing their
    values.

    This function traverses the linked list, summing values between zeros
    and updating the list in-place. It uses two pointers: one for traversal
    and another for updating the result. This approach allows for efficient
    memory usage as it modifies the existing list rather than creating a new
    one.

    The time complexity is O(n), where n is the number of nodes in the list,
    as we traverse each node exactly once. The space complexity is O(1) since
    we only use a constant amount of extra space for pointers and variables,
    regardless of the input size.
    """
    result_node = head
    traversal_node = head.next_node
    current_sum = 0

    while traversal_node:
        if traversal_node.val == 0:
            result_node = result_node.next_node
            result_node.val = current_sum
            current_sum = 0
        else:
            current_sum += traversal_node.val
        traversal_node = traversal_node.next_node

    result_node.next_node = None
    return head.next_node
```

{collapsible="true" default-state="expanded" collapsed-title="Two-Pointer Traversal with In-Place Modification Code..."}

#### Understanding the Core Idea {id="core-idea_d4_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to use two pointers to traverse the linked list while simultaneously modifying
it in-place.
This approach allows us to merge nodes between zeros efficiently without creating a new list.

- **Two-Pointer Technique:** The solution uses two pointers: `result_node` for building the modified list
  and `traversal_node` for iterating through the original list.
- **In-Place Modification:** Instead of creating a new list, the solution modifies the existing list, which saves space
  and simplifies the process.
- **Running Sum:** A `current_sum` variable is used to accumulate the sum of values between zeros.

> **Key Insight:**
> By using the existing nodes and only modifying their values, we can solve the problem without
> allocating any new memory for nodes, making the solution both time and space efficient.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d4_1" collapsible="true" default-state="expanded"}

1. **Initialization:**
   ```python
   result_node = head
   traversal_node = head.next_node
   current_sum = 0
   ```
   We initialize `result_node` to the head (which is a zero node), `traversal_node` to the next node to start
   processing, and `current_sum` to zero.
   This setup allows us to start summing from the first non-zero node.

2. **Traversal and Summing:**
   ```python
   while traversal_node:
       if traversal_node.val == 0:
           result_node = result_node.next_node
           result_node.val = current_sum
           current_sum = 0
       else:
           current_sum += traversal_node.val
       traversal_node = traversal_node.next_node
   ```
   This is the core of the algorithm.
   We traverse the list with `traversal_node`, summing values until we hit a zero.
   When we encounter a zero:
   - We move `result_node` to the next node (which will store our sum)
   - We set its value to the accumulated sum
   - We reset `current_sum` for the next group
     If the current node is not zero, we simply add its value to `current_sum`.

3. **Finalizing the List:**
   ```python
   result_node.next_node = None
   return head.next_node
   ```
   After the traversal, we set the `next_node` of the last result node to `None`, effectively trimming any remaining
   nodes.
   We return `head.next_node` because the original head was a zero node that we don't want in our final list.

---

#### Complexity Analysis {id="complexity-analysis_d4_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the original linked list.
  This is because we traverse the list exactly once, performing constant-time operations at each node.

**Space Complexity:**

- $O(1)$, as we are modifying the list in-place and only using a constant amount of extra space for our pointers and
  the `current_sum` variable, regardless of the input size.

---

#### Example {id="example_d4_1" collapsible="true" default-state="expanded"}

...

---

## July 5 -> 5. Problem Name {collapsible="true" default-state="collapsed"}

[Problem Statement]

---

### Approach 1: Approach Name {id="approach_d5_1" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d5_1" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d5_1" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d5_1" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d5_1" collapsible="true" default-state="expanded"}

...

---

### Approach 2: Approach Name {id="approach_d5_2" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d5_2" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d5_2" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d5_2" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d5_2" collapsible="true" default-state="expanded"}

...

---

## July 6 -> 6. Problem Name {collapsible="true" default-state="collapsed"}

[Problem Statement]

---

### Approach 1: Approach Name {id="approach_d6_1" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d6_1" collapsible="true" default-state="expanded"}

...

---

### Approach 2: Approach Name {id="approach_d6_2" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d6_2" collapsible="true" default-state="expanded"}

...

---

## July 7 -> 7. Problem Name {collapsible="true" default-state="collapsed"}

[Problem Statement]

---

### Approach 1: Approach Name {id="approach_d7_1" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d7_1" collapsible="true" default-state="expanded"}

...

---

### Approach 2: Approach Name {id="approach_d7_2" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d7_2" collapsible="true" default-state="expanded"}

...

---

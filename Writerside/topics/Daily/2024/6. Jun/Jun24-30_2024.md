# June 2024, Week 5: June 24th - June 30th

## June 24 -> 995. Minimum Number of K Consecutive Bit Flips {collapsible="true" default-state="collapsed"}

You are given a binary array `nums` and an integer `k`.

A **k-bit flip** is choosing a **subarray** of length `k` from `nums` and simultaneously changing every `0` in the
subarray to `1`, and every `1` in the subarray to `0`.

Return *the minimum number of **k-bit flips** required so that there is no* `0` *in the array*.
If it is not possible, return `-1`.

A **subarray** is a **contiguous** part of an array.

**Example 1:**

- **Input:** nums = [0,1,0], k = 1
- **Output:** 2
- **Explanation:** Flip nums[0], then flip nums[2].

**Example 2:**

- **Input:** nums = [1,1,0], k = 2
- **Output:** -1
- **Explanation:** No matter how we flip subarrays of size 2, we cannot make the array become [1,1,1].

**Example 3:**

- **Input:** nums = [0,0,0,1,0,1,1,0], k = 3
- **Output:** 3
- **Explanation:**
    - Flip nums[0],nums[1],nums[2]: nums becomes [1,1,1,1,0,1,1,0]
    - Flip nums[4],nums[5],nums[6]: nums becomes [1,1,1,1,1,0,0,0]
    - Flip nums[5],nums[6],nums[7]: nums becomes [1,1,1,1,1,1,1,1]

**Constraints:**

- `1 <= nums.length <= 10^5`
- `1 <= k <= nums.length`

---

### Approach 1: Sliding Window with Deque {id="approach_d1_1" collapsible="true" default-state="expanded"}

```Python
def minKBitFlips1(nums: List[int], k: int) -> int:
    """
    Determines the minimum number of k-bit flips required to convert all
    elements in `nums` to 1.

    This function uses a sliding window approach with a deque to efficiently
    track the flips. It maintains a 'current_flipped_state' to represent the
    cumulative effect of flips on the current element, avoiding the need to
    actually modify the input array. The algorithm iterates through the array
    once, deciding whether to flip at each position based on the current
    state and the original value. This approach allows for efficient handling
    of overlapping flips without the need to recalculate previous operations.

    The time complexity of this solution is O(n), where `n` is the length of
    `nums`, because it processes each element once with constant-time
    operations. The space complexity is O(k) due to the deque storing at most
    `k` elements to track the sliding window of flips.
    """
    if k == 1:
        return nums.count(0)  # Optimization for k=1 case

    flip_window_deque = deque()
    current_flipped_state = 0
    total_flips = 0

    for index, num in enumerate(nums):
        if index >= k:
            # Remove the effect of the flip that's now out of the window
            current_flipped_state ^= flip_window_deque.popleft()

        if current_flipped_state == num:
            # The current state matches the original value, so a flip is
            # needed
            if index + k > len(nums):
                return -1  # Not enough elements left for a flip
            flip_window_deque.append(1)
            current_flipped_state ^= 1
            total_flips += 1
        else:
            flip_window_deque.append(0)  # No flip needed at this position

    return total_flips
```

{collapsible="true" default-state="expanded" collapsed-title="Sliding Window with Deque Code..."}

#### Understanding the Core Idea {id="core-idea_d1_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage a sliding window approach with a deque to efficiently track k-bit
flips across the array.
This method allows for optimized handling of overlapping flips without modifying the original array.

- **Sliding Window:** A window of size `k` is used to manage the effect of flips on each element.
- **Deque for Flip Tracking:** A deque efficiently tracks whether a flip occurred at each position within the current
  window.
- **Current Flipped State:** This variable represents the cumulative effect of all flips on the current element.
- **Virtual Flips:** Instead of actually modifying the array, the algorithm virtually flips elements by tracking the
  flip state.

> **Key Insight:**
> The solution avoids the need to recalculate previous operations by maintaining a running state of
> flips, allowing for $O(n)$ time complexity despite potentially overlapping flip operations.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d1_1" collapsible="true" default-state="expanded"}

1. **Initialization and Edge Case Handling:**
   ```python
   if k == 1:
       return nums.count(0)
   
   flip_window_deque = deque()
   current_flipped_state = 0
   total_flips = 0
   ```
   The function starts with an optimization for `k=1`, simply counting the zeros.
   It then initializes the deque, the current flipped state, and the total flip count.

2. **Main Loop - Iterating Through the Array:**
   ```python
   for index, num in enumerate(nums):
   ```
   This loop processes each element of the array, deciding whether to flip at each position.

3. **Managing the Sliding Window:**
   ```python
   if index >= k:
       current_flipped_state ^= flip_window_deque.popleft()
   ```
   When the window size exceeds `k`, the effect of the oldest flip is removed using XOR operation.

4. **Flip Decision and Execution:**
   ```python
   if current_flipped_state == num:
       if index + k > len(nums):
           return -1
       flip_window_deque.append(1)
       current_flipped_state ^= 1
       total_flips += 1
   else:
       flip_window_deque.append(0)
   ```
   If the current state matches the original value, a flip is needed.
   The function checks if there's enough space for a flip, updates the deque and state, and increments the flip count.
   If no flip is needed, it appends 0 to the deque.

5. **Result Calculation/Return:**
   ```python
   return total_flips
   ```
   After processing all elements, the function returns the total number of flips performed.

---

#### Example {id="example_d1_1" collapsible="true" default-state="expanded"}

**Input:**

```python
nums = [0, 0, 0, 1, 0, 1, 1, 0]
k = 3
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - `flip_window_deque` is initialized as an empty deque: `deque([])`
    - `current_flipped_state` is set to 0
    - `total_flips` is set to 0

2. **Main Loop (Iterating through `nums`):**

    - **Iteration 1 (index 0, num = 0):**
        - `current_flipped_state` (0) == `num` (0), so a flip is needed
        - Add 1 to `flip_window_deque`: `deque([1])`
        - Update `current_flipped_state` to 1
        - Increment `total_flips` to 1

    - **Iteration 2 (index 1, num = 0):**
        - `current_flipped_state` (1) != `num` (0), no flip needed
        - Add 0 to `flip_window_deque`: `deque([1, 0])`

    - **Iteration 3 (index 2, num = 0):**
        - `current_flipped_state` (1) != `num` (0), no flip needed
        - Add 0 to `flip_window_deque`: `deque([1, 0, 0])`

    - **Iteration 4 (index 3, num = 1):**
        - Window size reached (`index >= k`), remove oldest flip: `deque([0, 0])`
        - Update `current_flipped_state` to 0
        - `current_flipped_state` (0) != `num` (1), no flip needed
        - Add 0 to `flip_window_deque`: `deque([0, 0, 0])`

    - **Iteration 5 (index 4, num = 0):**
        - Remove oldest flip: `deque([0, 0])`
        - `current_flipped_state` (0) == `num` (0), so a flip is needed
        - Add 1 to `flip_window_deque`: `deque([0, 0, 1])`
        - Update `current_flipped_state` to 1
        - Increment `total_flips` to 2

    - **Iteration 6 (index 5, num = 1):**
        - Remove oldest flip: `deque([0, 1])`
        - `current_flipped_state` (1) == `num` (1), so a flip is needed
        - Add 1 to `flip_window_deque`: `deque([0, 1, 1])`
        - Update `current_flipped_state` to 0
        - Increment `total_flips` to 3

    - **Iteration 7 (index 6, num = 1):**
        - Remove oldest flip: `deque([1, 1])`
        - `current_flipped_state` (0) != `num` (1), no flip needed
        - Add 0 to `flip_window_deque`: `deque([1, 1, 0])`

    - **Iteration 8 (index 7, num = 0):**
        - Remove oldest flip: `deque([1, 0])`
        - Update `current_flipped_state` to 1
        - `current_flipped_state` (1) != `num` (0), no flip needed
        - Add 0 to `flip_window_deque`: `deque([1, 0, 0])`

3. **Loop Termination:**
    - The loop ends after processing all elements in `nums`
    - Final state: `total_flips` = 3, `current_flipped_state` = 1, `flip_window_deque` = `deque([1, 0, 0])`

4. **Visual Aid:**

   Iteration Summary Table:

    | Index | Element | Flipped State | Total Flips | Flip Window |
    |-------|---------|---------------|-------------|-------------|
    | 0     | 0       | 1             | 1           | [1]         |
    | 1     | 0       | 1             | 1           | [1, 0]      |
    | 2     | 0       | 1             | 1           | [1, 0, 0]   |
    | 3     | 1       | 0             | 1           | [0, 0, 0]   |
    | 4     | 0       | 1             | 2           | [0, 0, 1]   |
    | 5     | 1       | 0             | 3           | [0, 1, 1]   |
    | 6     | 1       | 0             | 3           | [1, 1, 0]   |
    | 7     | 0       | 1             | 3           | [1, 0, 0]   |

5. **Result Calculation/Final Steps:**
    - The algorithm arrives at the final result by counting the total number of flips performed
    - The final result is the value of `total_flips`, which is 3

---

#### Complexity Analysis {id="complexity-analysis_d1_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the length of the input array `nums`.
  This is because the algorithm processes each element of the array exactly once,
  performing constant-time operations for each element.

**Space Complexity:**

- $O(k)$, where $k$ is the flip window size.
  This is due to the deque storing at most $k$ elements to track the sliding window of flips.
  The space used is independent of the input array size $n$, making it more efficient for large arrays
  with smaller $k$ values.

---

### Approach 2: In-place Tracking with Active Flips {id="approach_d1_3" collapsible="true" default-state="expanded"}

```Python
def minKBitFlips2(nums: List[int], k: int) -> int:
    """
    Computes the minimum number of k-bit flips needed to convert all
    elements in `nums` to 1.

    This function uses a clever in-place marking technique to track flips
    efficiently. It uses the value 2 to mark the start of a flip in the
    original array, allowing it to implicitly store flip information without
    additional data structures. The 'active_flips' variable keeps track of
    the number of active flips affecting the current element, enabling quick
    decisions on whether to flip. This approach combines the benefits of
    in-place modification with efficient flip tracking.

    The time complexity of this solution is O(n), where `n` is the length of
    `nums`, as it processes each element once with constant-time operations.
    The space complexity is O(1) since it modifies the input array in-place
    and uses only a constant amount of extra space.
    """
    if k == 1:
        return nums.count(0)  # Optimization for k=1 case

    n = len(nums)
    active_flips = 0
    total_flips = 0

    for index in range(n):
        if index >= k and nums[index - k] == 2:
            # A flip that started k positions ago is ending
            active_flips -= 1

        if (active_flips % 2) == nums[index]:
            # Current element needs to be flipped
            if index + k > n:
                return -1  # Not enough elements left for a flip
            nums[index] = 2  # Mark the start of a new flip
            active_flips += 1
            total_flips += 1

    return total_flips
```

{collapsible="true" default-state="expanded" collapsed-title="In-place Tracking with Active Flips Code..."}

#### Understanding the Core Idea {id="core-idea_d1_2" collapsible="true" default-state="expanded"}

The central concept of this solution is to use an in-place marking technique with clever bit manipulation to efficiently
track k-bit flips across the array.
This method combines the space efficiency of in-place modifications with an optimized approach
to handling overlapping flips.

- **In-place Marking:** The algorithm uses the value 2 to mark the start of a flip in the original array, enabling
  implicit storage of flip information without additional data structures.
- **Active Flips Tracking:** An `active_flips` variable keeps count of the number of active flips affecting the current
  element, allowing for quick flip decisions.
- **Parity-based Flip Detection:** The algorithm uses the parity of `active_flips` to determine whether the current
  element needs to be flipped.
- **Virtual Flips:** Instead of actually performing k-bit flips, the algorithm simulates their effect by tracking flip
  starts and active flip count.

> **Key Insight:**
> By using the value 2 as a flip marker and tracking active flips, the solution achieves $O(1)$ space
> complexity while efficiently handling overlapping flips, combining the benefits of previous approaches.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d1_2" collapsible="true" default-state="expanded"}

1. **Initialization and Edge Case Handling:**
   ```python
   if k == 1:
       return nums.count(0)
   
   n = len(nums)
   active_flips = 0
   total_flips = 0
   ```
   The function starts with an optimization for `k=1`, simply counting the zeros.
   It then initializes the length of the array, active flips count, and total flips count.

2. **Main Loop - Linear Scan:**
   ```python
   for index in range(n):
   ```
   This loop processes each element of the array, making flip decisions based on the current state and previous flips.

3. **Managing Active Flips:**
   ```python
   if index >= k and nums[index - k] == 2:
       active_flips -= 1
   ```

4. **Flip Decision and Execution:**
   ```python
   if (active_flips % 2) == nums[index]:
       if index + k > n:
           return -1
       nums[index] = 2
       active_flips += 1
       total_flips += 1
   ```
   If the parity of active flips matches the current element's value, a flip is needed.
   The function checks if there's enough space for a flip,
   marks the flip start with 2, and updates the active and total flip counts.

5. **Result Calculation/Return:**
   ```python
   return total_flips
   ```
   After processing all elements, the function returns the total number of flips performed.

> **Note:**
> While this approach does modify the input array during processing, it's possible to restore the original values.
> By subtracting 2 from `nums[i - k]` after decrementing `active_flips`,
> we can revert each modified element to its original state.
> This makes the modification temporary and allows us to preserve the input array if needed.
>
{style="tip"}


---

#### Example {id="example_d1_2" collapsible="true" default-state="expanded"}

**Input:**

```python
nums = [0, 0, 0, 1, 0, 1, 1, 0]
k = 3
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - `n` is set to 8 (length of `nums`)
    - `active_flips` is set to 0
    - `total_flips` is set to 0

2. **Main Loop (Iterating through `nums`):**

    - **Iteration 1 (index 0, num = 0):**
        - No flip ending (index < k)
        - `(active_flips % 2)` (0) == `nums[0]` (0), so a flip is needed
        - Mark flip start: `nums[0] = 2`
        - Increment `active_flips` to 1
        - Increment `total_flips` to 1

    - **Iteration 2 (index 1, num = 0):**
        - No flip ending (index < k)
        - `(active_flips % 2)` (1) != `nums[1]` (0), no flip needed

    - **Iteration 3 (index 2, num = 0):**
        - No flip ending (index < k)
        - `(active_flips % 2)` (1) != `nums[2]` (0), no flip needed

    - **Iteration 4 (index 3, num = 1):**
        - Flip ending: `nums[index - k]` (nums[0]) == 2
        - Decrement `active_flips` to 0
        - `(active_flips % 2)` (0) != `nums[3]` (1), no flip needed

    - **Iteration 5 (index 4, num = 0):**
        - No flip ending (`nums[1]` != 2)
        - `(active_flips % 2)` (0) == `nums[4]` (0), so a flip is needed
        - Mark flip start: `nums[4] = 2`
        - Increment `active_flips` to 1
        - Increment `total_flips` to 2

    - **Iteration 6 (index 5, num = 1):**
        - No flip ending (`nums[2]` != 2)
        - `(active_flips % 2)` (1) == `nums[5]` (1), so a flip is needed
        - Mark flip start: `nums[5] = 2`
        - Increment `active_flips` to 2
        - Increment `total_flips` to 3

    - **Iteration 7 (index 6, num = 1):**
        - No flip ending (`nums[3]` != 2)
        - `(active_flips % 2)` (0) != `nums[6]` (1), no flip needed

    - **Iteration 8 (index 7, num = 0):**
        - Flip ending: `nums[index - k]` (nums[4]) == 2
        - Decrement `active_flips` to 1
        - `(active_flips % 2)` (1) != `nums[7]` (0), no flip needed

3. **Loop Termination:**
    - The loop ends after processing all elements in `nums`
    - Final state: `total_flips` = 3, `active_flips` = 1

4. **Visual Aid:**

   Iteration Summary Table:

    | Index | Element Value | Active Flips | Total Flips |
    |-------|---------------|--------------|-------------|
    | 0     | 2             | 1            | 1           |
    | 1     | 0             | 1            | 1           |
    | 2     | 0             | 1            | 1           |
    | 3     | 1             | 0            | 1           |
    | 4     | 2             | 1            | 2           |
    | 5     | 2             | 2            | 3           |
    | 6     | 1             | 2            | 3           |
    | 7     | 0             | 1            | 3           |

5. **Result Calculation/Final Steps:**
    - The algorithm arrives at the final result by counting the total number of flips performed
    - The final result is the value of `total_flips`, which is 3

---

#### Complexity Analysis {id="complexity-analysis_d1_2" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where n is the length of the input array `nums`.
  This is because the algorithm processes each element of the array exactly once in the main loop,
  performing constant-time operations for each element.

**Space Complexity:**

- $O(1)$, as the algorithm uses only a constant amount of extra space regardless of the input size.
  It cleverly uses the input array itself to store flip information by marking flip starts with the value 2,
  avoiding the need for additional data structures that grow with the input size.

---

## June 25 -> 1038. Binary Search Tree to Greater Sum Tree {collapsible="true" default-state="collapsed"}

Given the `root` of a Binary Search Tree (BST), convert it to a Greater Tree such that every key of the original BST is
changed to the original key plus the sum of all keys greater than the original key in BST.

As a reminder, a *binary search tree* is a tree that satisfies these constraints:

- The left subtree of a node contains only nodes with keys **less than** the node's key.
- The right subtree of a node contains only nodes with keys **greater than** the node's key.
- Both the left and right subtrees must also be binary search trees.

**Example 1:**

![june24-2024-ex1.png](june24-2024-ex1-input.png)

- **Input:** root = [4,1,6,0,2,5,7,null,null,null,3,null,null,null,8]
- **Output:** [30,36,21,36,35,26,15,null,null,null,33,null,null,null,8]

![june24-2024-ex1.png](june24-2024-ex1-output.png)

**Example 2:**

![june24-2024-ex2.png](june24-2024-ex2-input.png)

- **Input:** root = [0,null,1]
- **Output:** [1,null,1]

![june24-2024-ex2.png](june24-2024-ex2-output.png)

**Constraints:**

- The number of nodes in the tree is in the range `[1, 100]`.
- `0 <= Node.val <= 100`
- All the values in the tree are **unique**.

---

### Approach 1: Recursive Reverse In-order Traversal {id="approach_d2_1" collapsible="true" default-state="expanded"}

```Python
def bstToGst1(root: TreeNode) -> TreeNode:
    """
    Converts a Binary Search Tree (BST) to a Greater Sum Tree (GST).

    This function performs an in-order traversal of the BST in reverse
    order (right-root-left), updating each node's value to be the sum of
    its original value plus all greater values in the tree. The algorithm
    leverages the BST property where all right subtree values are greater
    than the current node, and all left subtree values are smaller. By
    traversing right first, we accumulate the sum of greater values, which
    is then used to update the current node and propagated to the left
    subtree.

    The time complexity is O(n), where `n` is the number of nodes in the tree,
    as each node is visited exactly once. The space complexity is O(h), where
    `h` is the height of the tree, due to the recursive call stack. In the
    worst case of an unbalanced tree, this could be O(n) (skewed tree), but
    for a balanced BST, it would be O(log n).
    """
    cumulative_sum = 0

    def update_node_values(node: TreeNode) -> None:
        nonlocal cumulative_sum
        if node.right:
            update_node_values(node.right)
        cumulative_sum += node.val
        node.val = cumulative_sum
        if node.left:
            update_node_values(node.left)

    update_node_values(root)
    return root
```

{collapsible="true" default-state="expanded" collapsed-title="Recursive Reverse In-order Traversal Code..."}

#### Understanding the Core Idea {id="core-idea_d2_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage the properties of a Binary Search Tree (BST) to efficiently convert
it into a Greater Sum Tree (GST).
The solution uses a reverse in-order traversal (right-root-left) to accumulate the sum of greater values for each node.

- **BST Property Exploitation:** In a BST, all nodes in the right subtree have greater values than the current node, and
  all nodes in the left subtree have smaller values.
- **Reverse In-order Traversal:** By traversing the tree in a right-root-left order, we process larger values first,
  allowing us to accumulate the sum of greater values for each node.
- **Cumulative Sum Propagation:** As we traverse, we maintain a running sum of all greater values, updating each node's
  value with this sum plus its original value.

> **Key Insight:**
> The reverse in-order traversal allows us to process nodes in descending order of their values,
> naturally accumulating the sum of greater values without needing to store or recalculate these sums for each node.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d2_1" collapsible="true" default-state="expanded"}

1. **Initialization:**
   ```python
   cumulative_sum = 0
   ```
   A variable `cumulative_sum` is initialized to 0.
   This will be used to keep track of the running sum of greater values as we traverse the tree.

2. **Helper Function Definition:**
   ```python
   def update_node_values(node: TreeNode) -> None:
       nonlocal cumulative_sum
   ```
   An inner function `update_node_values` is defined to perform the recursive traversal and node value updates.
   It uses the `nonlocal` keyword to access and modify the `cumulative_sum` variable from the outer scope.

3. **Right Subtree Traversal:**
   ```python
   if node.right:
       update_node_values(node.right)
   ```
   The function first recursively processes the right subtree, ensuring that all greater values are processed before the
   current node.

4. **Node Value Update:**
   ```python
   cumulative_sum += node.val
   node.val = cumulative_sum
   ```
   After processing the right subtree, the current node's original value is added to `cumulative_sum`, and then the
   node's value is updated to be this new sum.

5. **Left Subtree Traversal:**
   ```python
   if node.left:
       update_node_values(node.left)
   ```
   Finally, the function recursively processes the left subtree, which will use the updated `cumulative_sum` that now
   includes the current node's original value.

6. **Traversal Initiation and Return:**
   ```python
   update_node_values(root)
   return root
   ```
   The traversal is started by calling `update_node_values` on the root node.
   After the traversal is complete, the modified root is returned.

---

#### Example {id="example_d2_1" collapsible="true" default-state="expanded"}

**Input:**

```python
# Binary Search Tree represented as:
root = TreeNode(4)
root.left = TreeNode(1)
root.right = TreeNode(6)
root.left.left = TreeNode(0)
root.left.right = TreeNode(2)
root.left.right.right = TreeNode(3)
root.right.left = TreeNode(5)
root.right.right = TreeNode(7)
root.right.right.right = TreeNode(8)
```

A visual representation of the input BST:

![june24-2024-ex1.png](june24-2024-ex1-input.png)

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - Set `cumulative_sum = 0`
    - Call `update_node_values(root)` with the root node (4)

2. **Main Loop (Reverse In-order Traversal):**

    - **Iteration 1 (Node 4):**
        - Move to right child (6)

    - **Iteration 2 (Node 6):**
        - Move to right child (7)

    - **Iteration 3 (Node 7):**
        - Move to right child (8)

    - **Iteration 4 (Node 8):**
        - No right child, process node
        - Update `cumulative_sum`: 0 + 8 = 8
        - Set node value to 8
        - No left child, return to parent (7)

    - **Iteration 5 (Node 7):**
        - Update `cumulative_sum`: 8 + 7 = 15
        - Set node value to 15
        - No left child, return to parent (6)

    - **Iteration 6 (Node 6):**
        - Update `cumulative_sum`: 15 + 6 = 21
        - Set node value to 21
        - Move to left child (5)

    - **Iteration 7 (Node 5):**
        - No right child, process node
        - Update `cumulative_sum`: 21 + 5 = 26
        - Set node value to 26
        - No left child, return to parent (6), then to grandparent (4)

    - **Iteration 8 (Node 4):**
        - Update `cumulative_sum`: 26 + 4 = 30
        - Set node value to 30
        - Move to left child (1)

    - **Iteration 9 (Node 1):**
        - Move to right child (2)

    - **Iteration 10 (Node 2):**
        - Move to right child (3)

    - **Iteration 11 (Node 3):**
        - No right child, process node
        - Update `cumulative_sum`: 30 + 3 = 33
        - Set node value to 33
        - No left child, return to parent (2)

    - **Iteration 12 (Node 2):**
        - Update `cumulative_sum`: 33 + 2 = 35
        - Set node value to 35
        - No left child, return to parent (1)

    - **Iteration 13 (Node 1):**
        - Update `cumulative_sum`: 35 + 1 = 36
        - Set node value to 36
        - Move to left child (0)

    - **Iteration 14 (Node 0):**
        - No right child, process node
        - Update `cumulative_sum`: 36 + 0 = 36
        - Set node value to 36
        - No left child, return to parent (1), then to grandparent (4)

3. **Loop Termination:**
    - The traversal is complete when we return to the root node (4) and there are no more nodes to visit
    - Final `cumulative_sum` is 36

4. **Visual Aid:**

   **Iteration Summary Table:**

    | Original Value | Added to Sum | New Value (Cumulative Sum) |
    |----------------|--------------|----------------------------|
    | 8              | 0            | 8                          |
    | 7              | 8            | 15                         |
    | 6              | 15           | 21                         |
    | 5              | 21           | 26                         |
    | 4              | 26           | 30                         |
    | 3              | 30           | 33                         |
    | 2              | 33           | 35                         |
    | 1              | 35           | 36                         |
    | 0              | 36           | 36                         |

5. **Result Calculation/Final Steps:**
    - The algorithm has modified the BST in-place
    - Each node's value now represents the sum of its original value and all greater values in the original BST
    - The root node (originally 4) now has the value 30, which is the sum of 4 and all greater values (5, 6, 7, 8)
    - The resulting Greater Sum Tree maintains the BST structure but with updated node values

The final Greater Sum Tree looks like this:

![june24-2024-ex1.png](june24-2024-ex1-output.png)

---

#### Complexity Analysis {id="complexity-analysis_d2_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree.
  This is because each node in the tree is visited exactly once during the traversal.

**Space Complexity:**

- $O(h)$, where $h$ is the height of the tree.
  This space is used by the recursive call stack.
  In the worst case of an unbalanced tree (skewed tree), this could be $O(n)$, but for a balanced BST,
  it would be $O(\log n)$.

The space complexity is determined by the maximum depth of the recursive call stack, which corresponds to the height of
the tree.
Each recursive call adds a frame to the call stack, and the maximum number of simultaneous frames is equal to the
height of the tree.

---

### Approach 2: Iterative Reverse In-order Traversal with Stack {id="approach_d2_2" collapsible="true" default-state="expanded"}

```Python
def bstToGst2(root: TreeNode) -> TreeNode:
    """
    Converts a Binary Search Tree (BST) to a Greater Sum Tree (GST).

    This function performs an in-order traversal of the BST in reverse
    order (right-root-left) using a stack, updating each node's value to
    be the sum of its original value plus all greater values in the tree.
    The algorithm uses an explicit stack to simulate the recursive process,
    pushing all right nodes onto the stack first, then processing the current
    node, and finally pushing left nodes. This approach maintains the
    property of visiting nodes in descending order of value.

    The time complexity is O(n), where `n` is the number of nodes in the tree,
    as each node is visited exactly once. The space complexity is O(h), where
    `h` is the height of the tree, due to the stack used for traversal. In
    the worst case of an unbalanced tree, this could be O(n) (skewed tree),
    but for a balanced BST, it would be O(log n).
    """
    def push_right_nodes(node: TreeNode) -> None:
        """Helper function to push all right nodes onto the stack."""
        while node:
            stack.append(node)
            node = node.right

    stack = []
    current_node = root
    cumulative_sum = 0

    push_right_nodes(current_node)

    while stack:
        current_node = stack.pop()
        cumulative_sum += current_node.val
        current_node.val = cumulative_sum
        push_right_nodes(current_node.left)

    return root
```

{collapsible="true" default-state="expanded" collapsed-title="Iterative Reverse In-order Traversal with Stack Code..."}

#### Understanding the Core Idea {id="core-idea_d2_2" collapsible="true" default-state="expanded"}

The central concept of this solution is to convert a Binary Search Tree (BST) to a Greater Sum Tree (GST) using an
iterative approach with a stack.
This method simulates the reverse in-order traversal (right-root-left) without using recursion.

- **Iterative Traversal:** Instead of recursion, the solution uses a stack to keep track of nodes to be processed,
  allowing for an iterative implementation.
- **Right-First Approach:** By pushing all right nodes onto the stack first, the algorithm ensures that larger values
  are processed before smaller ones.
- **Cumulative Sum Propagation:** As in the recursive version, a running sum is maintained and used to update node
  values.

> **Key Insight:**
> The use of a stack and the `push_right_nodes` helper function allows for an elegant iterative solution
> that maintains the descending order processing of nodes, crucial for the GST conversion.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d2_2" collapsible="true" default-state="expanded"}

1. **Helper Function Definition:**
   ```python
   def push_right_nodes(node: TreeNode) -> None:
       while node:
           stack.append(node)
           node = node.right
   ```
   This helper function pushes all right child nodes of a given node onto the stack.
   It's crucial for maintaining the right-root-left traversal order.

2. **Initialization:**
   ```python
   stack = []
   current_node = root
   cumulative_sum = 0
   ```
   A stack is initialized to store nodes, `current_node` is set to the root, and `cumulative_sum` is initialized to 0 to
   keep track of the running sum.

3. **Initial Stack Population:**
   ```python
   push_right_nodes(current_node)
   ```
   The stack is initially populated with the root and all its right descendants.

4. **Main Traversal Loop:**
   ```python
   while stack:
   ```
   The main loop continues as long as there are nodes in the stack to process.

5. **Node Processing:**
   ```python
   current_node = stack.pop()
   cumulative_sum += current_node.val
   current_node.val = cumulative_sum
   ```
   For each node, we pop it from the stack, add its value to the cumulative sum, and then update its value with this new
   sum.

6. **Left Subtree Handling:**
   ```python
   push_right_nodes(current_node.left)
   ```
   After processing a node, we push all right descendants of its left child onto the stack.
   This ensures that we process the left subtree after the current node, maintaining the reverse in-order traversal.

7. **Result Return:**
   ```python
   return root
   ```
   After processing all nodes, the modified root is returned.

---

#### Example {id="example_d2_2" collapsible="true" default-state="expanded"}

**Input:**

```python
# Binary Search Tree represented as:
root = TreeNode(4)
root.left = TreeNode(1)
root.right = TreeNode(6)
root.left.left = TreeNode(0)
root.left.right = TreeNode(2)
root.left.right.right = TreeNode(3)
root.right.left = TreeNode(5)
root.right.right = TreeNode(7)
root.right.right.right = TreeNode(8)
```

A visual representation of the input BST:

![june24-2024-ex1.png](june24-2024-ex1-input.png)

**Step-by-Step Walkthrough:**

1. **Initialization:**
    - Initialize an empty `stack = []`
    - Set `current_node = root` (4)
    - Set `cumulative_sum = 0`

2. **Initial Stack Population:**
    - Call `push_right_nodes(current_node)`
        - Push 4 onto the stack
        - Move to right child: 6
        - Push 6 onto the stack
        - Move to right child: 7
        - Push 7 onto the stack
        - Move to right child: 8
        - Push 8 onto the stack
        - No more right children
    - Stack after pushing: [4, 6, 7, 8]

3. **Main Traversal Loop:**

    - **Iteration 1 (Node 8):**
        - Pop 8 from the stack
        - Update `cumulative_sum`: 0 + 8 = 8
        - Set node value to 8
        - No left child to process

    - **Iteration 2 (Node 7):**
        - Pop 7 from the stack
        - Update `cumulative_sum`: 8 + 7 = 15
        - Set node value to 15
        - No left child to process

    - **Iteration 3 (Node 6):**
        - Pop 6 from the stack
        - Update `cumulative_sum`: 15 + 6 = 21
        - Set node value to 21
        - Process left child (5):
            - Push 5 onto the stack
        - Stack after pushing: [4, 5]

    - **Iteration 4 (Node 5):**
        - Pop 5 from the stack
        - Update `cumulative_sum`: 21 + 5 = 26
        - Set node value to 26
        - No left child to process

    - **Iteration 5 (Node 4):**
        - Pop 4 from the stack
        - Update `cumulative_sum`: 26 + 4 = 30
        - Set node value to 30
        - Process left child (1):
            - Push 1 onto the stack
            - Move to right child: 2
            - Push 2 onto the stack
            - Move to right child: 3
            - Push 3 onto the stack
        - Stack after pushing: [1, 2, 3]

    - **Iteration 6 (Node 3):**
        - Pop 3 from the stack
        - Update `cumulative_sum`: 30 + 3 = 33
        - Set node value to 33
        - No left child to process

    - **Iteration 7 (Node 2):**
        - Pop 2 from the stack
        - Update `cumulative_sum`: 33 + 2 = 35
        - Set node value to 35
        - No left child to process

    - **Iteration 8 (Node 1):**
        - Pop 1 from the stack
        - Update `cumulative_sum`: 35 + 1 = 36
        - Set node value to 36
        - Process left child (0):
            - Push 0 onto the stack
        - Stack after pushing: [0]

    - **Iteration 9 (Node 0):**
        - Pop 0 from the stack
        - Update `cumulative_sum`: 36 + 0 = 36
        - Set node value to 36
        - No left child to process

4. **Visual Aid:**

   **Iteration Summary Table:**

   | Original Value | Added to Sum | New Value (Cumulative Sum) |
   |----------------|--------------|----------------------------|
   | 8              | 0            | 8                          |
   | 7              | 8            | 15                         |
   | 6              | 15           | 21                         |
   | 5              | 21           | 26                         |
   | 4              | 26           | 30                         |
   | 3              | 30           | 33                         |
   | 2              | 33           | 35                         |
   | 1              | 35           | 36                         |
   | 0              | 36           | 36                         |

5. **Result Calculation/Final Steps:**
    - The algorithm has modified the BST in-place
    - Each node's value now represents the sum of its original value and all greater values in the original BST
    - The root node (originally 4) now has the value 30, which is the sum of 4 and all greater values (5, 6, 7, 8)
    - The resulting Greater Sum Tree maintains the BST structure but with updated node values

The final Greater Sum Tree looks like this:

![june24-2024-ex1.png](june24-2024-ex1-output.png)

This iterative approach using a stack achieves the same result as the recursive method, converting the BST to a Greater
Sum Tree by updating each node's value to be the sum of its original value and all greater values in the tree.

---

#### Complexity Analysis {id="complexity-analysis_d2_2" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree.
  Each node is visited exactly once during the traversal.
  Although we have a nested loop (the `while` loop in `push_right_nodes` inside the main `while` loop),
  each node is still pushed and popped from the stack exactly once.

**Space Complexity:**

- $O(h)$, where h is the height of the tree.
  The stack uses this space to store nodes during traversal.
  In the worst case of an unbalanced tree (skewed tree), this could be $O(n)$,
  but for a balanced BST, it would be $O(\log n)$.

The space complexity is determined by the maximum number of nodes that can be on the stack at any given time.
This corresponds to the height of the tree because, at most, we will have a path from the root to a leaf on the stack.

---

### Approach 3: Morris Traversal {id="approach_d2_3" collapsible="true" default-state="expanded"}

```Python
def bstToGst3(root: TreeNode) -> TreeNode:
    """
    Converts a Binary Search Tree (BST) to a Greater Sum Tree (GST).
    
    This function performs a reverse in-order traversal (right-root-left) of
    the BST using Morris Traversal, updating each node's value to be the sum
    of its original value plus all greater values in the tree. The algorithm
    uses a threaded binary tree approach, temporarily modifying the tree
    structure to navigate without recursion or an explicit stack.

    The Morris Traversal creates temporary links from the successor node
    (leftmost node of the right subtree) to the current node, allowing
    backtracking without using a stack. These temporary links are removed
    after use, restoring the original tree structure.

    The time complexity is O(n), where `n` is the number of nodes in the tree.
    Although each node may be visited up to three times (to create the link,
    to process the node, and to remove the link), this still results in linear
    time complexity. The space complexity is O(1) as it uses only a constant
    amount of extra space, regardless of the tree size.
    """

        def find_successor(current_node: TreeNode) -> TreeNode:
        """
        Helper function to find the inorder successor in the context of
        reverse inorder traversal. This is the leftmost node in the right
        subtree of the current node.
        """
        successor = current_node.right
        while successor.left and successor.left is not current_node:
            successor = successor.left
        return successor

    cumulative_sum = 0
    current_node = root
    while current_node:
        if not current_node.right:
            # No right child: process the current node and move to the left
            cumulative_sum += current_node.val
            current_node.val = cumulative_sum
            current_node = current_node.left
        else:
            successor = find_successor(current_node)
            if not successor.left:
                # First time visiting: create a temporary link and move right
                successor.left = current_node
                current_node = current_node.right
            else:
                # Second time visiting: remove temp link, process node, and
                # move left
                successor.left = None
                cumulative_sum += current_node.val
                current_node.val = cumulative_sum
                current_node = current_node.left

    return root
```

{collapsible="true" default-state="expanded" collapsed-title="Morris Traversal Code..."}

#### Understanding the Core Idea {id="core-idea_d2_3" collapsible="true" default-state="expanded"}

The central concept of this solution is to convert a Binary Search Tree (BST) to a Greater Sum Tree (GST) using the
Morris Traversal algorithm.
This method performs a reverse in-order traversal (right-root-left) without using recursion or an explicit stack,
achieving $O(1)$ space complexity.

- **Morris Traversal:** This technique creates temporary links in the tree to facilitate navigation without additional
  data structures.
- **Threaded Binary Tree:** The algorithm temporarily modifies the tree structure, creating links from successor nodes
  to their predecessors.
- **Constant Space:** By using these temporary links, the traversal is performed using only a constant amount of extra
  space, regardless of tree size.

> **Key Insight:**
> The Morris Traversal cleverly uses the empty left child pointers of successor nodes to create temporary
> backlinks, allowing for a stackless and recursion-free traversal while maintaining the correct visitation order for
> GST conversion.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d2_3" collapsible="true" default-state="expanded"}

1. **Helper Function Definition:**
   ```python
   def find_successor(current_node: TreeNode) -> TreeNode:
       successor = current_node.right
       while successor.left and successor.left is not current_node:
           successor = successor.left
       return successor
   ```
   This function finds the inorder successor (leftmost node of the right subtree) of the current node in the context of
   reverse inorder traversal.

2. **Initialization:**
   ```python
   cumulative_sum = 0
   current_node = root
   ```
   `cumulative_sum` is initialized to keep track of the running sum, and `current_node` is set to the root to begin
   traversal.

3. **Main Traversal Loop:**
   ```python
   while current_node:
   ```
   The main loop continues as long as there's a current node to process.

4. **No Right Child Case:**
   ```python
   if not current_node.right:
       cumulative_sum += current_node.val
       current_node.val = cumulative_sum
       current_node = current_node.left
   ```
   If there's no right child, we process the current node and move to the left.

5. **Right Child Exists Case:**
   ```python
   else:
       successor = find_successor(current_node)
   ```
   If a right child exists, we find the successor node.

6. **First Visit to Successor:**
   ```python
   if not successor.left:
       successor.left = current_node
       current_node = current_node.right
   ```
   On the first visit, we create a temporary link from the successor to the current node and move right.

7. **Second Visit to Successor:**
   ```python
   else:
       successor.left = None
       cumulative_sum += current_node.val
       current_node.val = cumulative_sum
       current_node = current_node.left
   ```
   On the second visit, we remove the temporary link, process the current node, and move left.

8. **Result Return:**
   ```python
   return root
   ```
   After processing all nodes, the modified root is returned.

---

#### Example {id="example_d2_3" collapsible="true" default-state="expanded"}

**Input:**

```python
# Binary Search Tree represented as:
root = TreeNode(4)
root.left = TreeNode(1)
root.right = TreeNode(6)
root.left.left = TreeNode(0)
root.left.right = TreeNode(2)
root.left.right.right = TreeNode(3)
root.right.left = TreeNode(5)
root.right.right = TreeNode(7)
root.right.right.right = TreeNode(8)
```

A visual representation of the input BST:

![june24-2024-ex1.png](june24-2024-ex1-input.png)

**Step-by-Step Walkthrough:**

1. **Initialization:**
   - Set `cumulative_sum = 0`
   - Set `current_node = root` (4)

2. **Main Traversal Loop:**

   - **Processing Node 4:**
      - Find successor: 5 (leftmost node of right subtree)
      - Create temporary link: 5.left = 4
      - Move to right child: 6

   - **Processing Node 6:**
      - Find successor: 7
      - Create temporary link: 7.left = 6
      - Move to right child: 7

   - **Processing Node 7:**
      - Find successor: 8
      - Create temporary link: 8.left = 7
      - Move to right child: 8

   - **Processing Node 8:**
      - No right child
      - Update node: 8 + 0 = 8
      - Move to left child: 7

   - **Processing Node 7 (second visit):**
      - Remove temporary link: 8.left = None
      - Update node: 7 + 8 = 15
      - Move to left child: 6

   - **Processing Node 6 (second visit):**
      - Remove temporary link: 15.left = None
      - Update node: 6 + 15 = 21
      - Move to left child: 5

   - **Processing Node 5:**
      - No right child
      - Update node: 5 + 21 = 26
      - Move to left child: 4

   - **Processing Node 4 (second visit):**
      - Remove temporary link: 26.left = None
      - Update node: 4 + 26 = 30
      - Move to left child: 1

   - **Processing Node 1:**
      - Find successor: 2
      - Create temporary link: 2.left = 1
      - Move to right child: 2

   - **Processing Node 2:**
      - Find successor: 3
      - Create temporary link: 3.left = 2
      - Move to right child: 3

   - **Processing Node 3:**
      - No right child
      - Update node: 3 + 30 = 33
      - Move to left child: 2

   - **Processing Node 2 (second visit):**
      - Remove the temporary link: 33.left = None
      - Update node: 2 + 33 = 35
      - Move to left child: 1

   - **Processing Node 1 (second visit):**
      - Remove the temporary link: 35.left = None
      - Update node: 1 + 35 = 36
      - Move to left child: 0

   - **Processing Node 0:**
      - No right child
      - Update node: 0 + 36 = 36
      - Move to left child: None (Traversal complete)

3. **Visual Aid:**

   **Iteration Summary Table:**

   | Original Value | Added to Sum | New Value (Cumulative Sum) |
   |----------------|--------------|----------------------------|
   | 8              | 0            | 8                          |
   | 7              | 8            | 15                         |
   | 6              | 15           | 21                         |
   | 5              | 21           | 26                         |
   | 4              | 26           | 30                         |
   | 3              | 30           | 33                         |
   | 2              | 33           | 35                         |
   | 1              | 35           | 36                         |
   | 0              | 36           | 36                         |

4. **Result Calculation/Final Steps:**
   - The algorithm has modified the BST in-place
   - Each node's value now represents the sum of its original value and all greater values in the original BST
   - The root node (originally 4) now has the value 30, which is the sum of 4 and all greater values (5, 6, 7, 8)
   - The resulting Greater Sum Tree maintains the BST structure but with updated node values
   - All temporary links created during the traversal have been removed, restoring the original tree structure

The final Greater Sum Tree looks like this:

![june24-2024-ex1.png](june24-2024-ex1-output.png)

This Morris Traversal approach achieves the same result as the recursive and stack-based methods, converting the BST to
a Greater Sum Tree.
It does so without using additional data structures (like a stack) or recursive calls,
maintaining $O(1)$ space complexity while still achieving $O(n)$ time complexity.

---

#### Complexity Analysis {id="complexity-analysis_d2_3" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree.
  Although each node may be visited up to three times (to create the link, to process the node, and to remove the link),
  this still results in linear time complexity.
  The total number of operations is proportional to the number of nodes.

**Space Complexity:**

- $O(1)$, constant space.
  This is the key advantage of Morris Traversal.
  It uses only a constant amount of extra space, regardless of the tree size.
  The temporary modifications to the tree structure do not count towards space complexity
  as they are made within the existing tree nodes and are reverted during the traversal.

The constant space complexity is achieved by using the existing tree structure to simulate the traversal stack, avoiding
the need for additional data structures that grow with the size of the input.

---

## June 26 -> 1382. Balance a Binary Search Tree {collapsible="true" default-state="collapsed"}

Given the `root` of a binary search tree, return *a **balanced** binary search tree with the same node values*.
If there is more than one answer, return **any of them**.

A binary search tree is **balanced** if the depth of the two subtrees of every node never differs by more than `1`.

**Example 1:**

![june25-2024-ex1.png](june25-2024-ex1.png)

- **Input:** root = [1,null,2,null,3,null,4,null,null]
- **Output:** [2,1,3,null,null,null,4]
- **Explanation:** This is not the only correct answer, [3,1,4,null,2] is also correct.

**Example 2:**

![june25-2024-ex2.png](june25-2024-ex2.png)

- **Input:** root = [2,1,3]
- **Output:** [2,1,3]

**Constraints:**

- The number of nodes in the tree is in the range `[1, 10^4]`.
- `1 <= Node.val <= 10^5`

---

### Approach 1: In-Order Traversal and Recursive Reconstruction {id="approach_d3_1" collapsible="true" default-state="expanded"}

```Python
def balanceBST1(root: TreeNode) -> TreeNode:
    """
    Converts an unbalanced binary search tree (BST) into a balanced one.

    This function uses a two-step approach to balance the BST:
    1. It performs an in-order traversal of the original BST, storing nodes
       in a list. This step ensures that we have a sorted list of nodes, as
       in-order traversal of a BST yields nodes in ascending order.
    2. It then recursively constructs a new balanced BST from this sorted
       list, using the middle element as the root at each step. This approach
       guarantees that the tree remains balanced, as we always choose the
       median element as the root.

    The time complexity of this solution is O(n), where `n` is the number of
    nodes in the tree. This is because we traverse each node once during the
    in-order traversal and once during the balanced BST construction.
    The space complexity is O(n) as well, due to the storage of all nodes in
    the `inorder_nodes` list and the recursion stack used in both traversal
    and construction.
    """
    inorder_nodes = []

    def inorder_traverse(root: TreeNode) -> None:
        """Helper function to perform in-order traversal of the tree."""
        if not root:
            return
        inorder_traverse(root.left)
        inorder_nodes.append(root)
        inorder_traverse(root.right)

    def build_balanced_bst(start_index: int,
                           end_index: int) -> TreeNode | None:
        """
        Helper function to construct a balanced BST from the sorted list of
        nodes.
        """
        if start_index > end_index:
            return None

        mid_index = start_index + (end_index - start_index) // 2

        node = inorder_nodes[mid_index]
        node.left = build_balanced_bst(start_index, mid_index - 1)
        node.right = build_balanced_bst(mid_index + 1, end_index)
        return node

    inorder_traverse(root)
    return build_balanced_bst(0, len(inorder_nodes) - 1)
```

{collapsible="true" default-state="expanded" collapsed-title="In-Order Traversal and Recursive Reconstruction Code..."}

#### Understanding the Core Idea {id="core-idea_d3_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage the properties of Binary Search Trees (BSTs) and in-order traversal
to create a balanced BST.
This approach consists of two main steps:

1. **In-Order Traversal:** Perform an in-order traversal of the original BST to get a sorted list of nodes.
2. **Recursive Reconstruction:** Use the sorted list to recursively construct a new balanced BST.

- **BST Property Exploitation:** In-order traversal of a BST yields nodes in ascending order, which is crucial for the
  balancing step.
- **Divide and Conquer:** The reconstruction phase uses a divide-and-conquer approach, selecting the median element as
  the root at each step to ensure balance.

> **Key Insight:**
> By using the middle element of the sorted list as the root at each recursive step, we guarantee that
> the resulting tree is balanced, as the number of nodes in the left and right subtrees differ by at most one at each
> level.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d3_1" collapsible="true" default-state="expanded"}

1. **Initialization and Helper Function Definitions:**
   ```python
   def balanceBST1(root: TreeNode) -> TreeNode:
       inorder_nodes = []

       def inorder_traverse(root: TreeNode) -> None:
           # ... (implementation details in step 2)

       def build_balanced_bst(start_index: int, 
                              end_index: int) -> TreeNode | None:
           # ... (implementation details in step 3)
   ```
   The main function `balanceBST1` is defined, along with an empty list `inorder_nodes` to store the sorted nodes.
   Two helper functions, `inorder_traverse` and `build_balanced_bst` are also defined within the main function's scope.

2. **In-Order Traversal:**
   ```python
   def inorder_traverse(root: TreeNode) -> None:
       if not root:
           return
       inorder_traverse(root.left)
       inorder_nodes.append(root)
       inorder_traverse(root.right)
   ```
   This helper function performs an in-order traversal of the original BST.
   It recursively visits the left subtree, appends the current node to `inorder_nodes`, and then visits the
   right subtree.
   This results in a list of nodes sorted in ascending order.

3. **Balanced BST Construction:**
   ```python
   def build_balanced_bst(start_index: int,
                          end_index: int) -> TreeNode | None:
       if start_index > end_index:
           return None

       mid_index = start_index + (end_index - start_index) // 2

       node = inorder_nodes[mid_index]
       node.left = build_balanced_bst(start_index, mid_index - 1)
       node.right = build_balanced_bst(mid_index + 1, end_index)
       return node
   ```
   This helper function recursively constructs a balanced BST from the sorted list of nodes.
   It selects the middle element as the root, recursively builds the left subtree from nodes before the middle,
   and the right subtree from nodes after the middle.

4. **Execution and Return:**
   ```python
   inorder_traverse(root)
   return build_balanced_bst(0, len(inorder_nodes) - 1)
   ```
   Finally, the main function executes the in-order traversal on the input tree and then calls `build_balanced_bst` to
   construct and return the balanced BST.

---

#### Example {id="example_d3_1" collapsible="true" default-state="expanded"}

**Input:**
```python
root = TreeNode(4)
root.left = TreeNode(3)
root.left.left = TreeNode(2)
root.left.left.left = TreeNode(1)
```

A visual representation of the input BST:

![june26-2024-ap1-input_1.png](june26-2024-ap1-input.png)

**Step-by-Step Walkthrough:**

1. **Initialization:**
   - An empty list `inorder_nodes` is created to store the nodes in sorted order.

2. **In-order Traversal:**

   - **Node 4:**
      - The function starts at the root node with value 4.
      - It moves to the left child (node 3).

   - **Node 3:**
      - The function moves to the left child (node 2).

   - **Node 2:**
      - The function moves to the left child (node 1).

   - **Node 1:**
      - The function checks the left child, which is `None`.
      - Node 1 is appended to `inorder_nodes`.
        - `inorder_nodes = [1]` 
      - The function checks the right child, which is `None`.
      - The function returns to node 2.

   - **Back to Node 2:**
      - Node 2 is appended to `inorder_nodes`.
        - `inorder_nodes = [1, 2]` 
      - The function checks the right child, which is `None`.
      - The function returns to node 3.

   - **Back to Node 3:**
      - Node 3 is appended to `inorder_nodes`.
        - `inorder_nodes = [1, 2, 3]` 
      - The function checks the right child, which is `None`.
      - The function returns to node 4.

   - **Back to Node 4:**
      - Node 4 is appended to `inorder_nodes`.
        - `inorder_nodes = [1, 2, 3, 4]`
      - The function checks the right child, which is `None`.
      - The in-order traversal is complete.

3. **Building Balanced BST:**

   - **Initial Call:**
      - `start_index = 0`, `end_index = 3`
      - `mid_index = 1`
      - Root node is set to `inorder_nodes[1]` (value 2)
      - Left and right subtrees are recursively constructed.
        - Left subtree: from `start_index` to `mid_index - 1` (0 to 0)
        - Right subtree: from `mid_index + 1` to `end_index` (2 to 3)

   - **Left Subtree (0, 0):**
      - `start_index = 0`, `end_index = 0`
      - `mid_index = 0`
      - Node with value 1 becomes the left child of 2
      - Its left and right children are set to `None` because the index range will be invalid

   - **Right Subtree (2, 3):**
      - `start_index = 2`, `end_index = 3`
      - `mid_index = 2`
      - Node with value 3 becomes the right child of 2
      - Left and right subtrees are recursively constructed.
        - Left subtree: from `start_index` to `mid_index - 1` (2 to 1) - Invalid range
        - Right subtree: from `mid_index + 1` to `end_index` (3 to 3)

   - **Right Subtree of 3 (3, 3):**
      - `start_index = 3`, `end_index = 3`
      - `mid_index = 3`
      - Node with value 4 becomes the right child of 3
      - Its left and right children are set to `None` because the index range will be invalid

4. **Result Calculation:**
   - The function returns the root of the new balanced BST (node with value 2).
   - The depth of every node in the new tree differs by at most 1, satisfying the balance condition.
   
A visual representation of the output Balanced BST:

![june26-2024-ap1-output.png](june26-2024-ap1-output.png)

---

#### Complexity Analysis {id="complexity-analysis_d3_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree. This is because:
   1. The in-order traversal visits each node once: $O(n)$
   2. The balanced BST construction processes each node once: $O(n)$
   3. The total time is the sum of these operations: $O(n) + O(n) = O(n)$

**Space Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree. This is because:
   1. The `inorder_nodes` list stores all n nodes: $O(n)$
   2. The recursion stack in both traversal and construction can go up to $O(\log n)$ in the balanced case, but $O(n)$
      in the worst case (skewed tree)
   3. The total space is dominated by the largest of these: $O(n)$

---

### Approach 2: Day-Stout-Warren (DSW) Algorithm {id="approach_d3_2" collapsible="true" default-state="expanded"}

```Python
def balanceBST2(root: TreeNode) -> TreeNode:
    """
    Converts an unbalanced binary search tree (BST) into a balanced one.

    This function implements the Day-Stout-Warren (DSW) algorithm to balance
    a BST in three main steps:
    1. Convert the BST into a "vine" (a right-skewed tree)
    2. Determine the number of nodes needed for a perfect binary tree
    3. Perform a series of left rotations to balance the tree

    The DSW algorithm achieves balance through a series of tree rotations,
    without requiring extra space for node storage. It guarantees a balanced
    tree with a height of O(log n).

    The time complexity of this solution is O(n), where `n` is the number of
    nodes. Despite multiple passes through the tree, each node is processed a
    constant number of times.
    The space complexity is O(1), as it uses only a constant amount of extra
    space, regardless of the input size. This is a key advantage over methods
    that require O(n) auxiliary space.
    """
    def right_rotate(parent: TreeNode, node: TreeNode) -> None:
        """Helper function to perform a right rotation on the given node."""
        left_child = node.left
        node.left = left_child.right
        left_child.right = node
        parent.right = left_child

    def left_rotate(parent: TreeNode, node: TreeNode) -> None:
        """Helper function to perform a left rotation on the given node."""
        right_child = node.right
        node.right = right_child.left
        right_child.left = node
        parent.right = right_child

    def compress_vine(vine_root: TreeNode, rotations: int) -> None:
        """Helper function to perform a series of left rotations to balance the vine."""
        current_node = vine_root
        for _ in range(rotations):
            child = current_node.right
            left_rotate(current_node, child)
            current_node = current_node.right

    dummy_root = TreeNode()
    dummy_root.right = root
    current_node = dummy_root

    # Step 1: Convert BST to vine (right-leaning linked list)
    while current_node.right:
        if current_node.right.left:
            right_rotate(current_node, current_node.right)
        else:
            current_node = current_node.right

    # Step 2: Count nodes and calculate perfect tree size
    node_count = 0
    current_node = dummy_root.right
    while current_node:
        node_count += 1
        current_node = current_node.right

    # Calculate the number of nodes in the perfect tree portion
    perfect_tree_nodes = 2 ** math.floor(math.log2(node_count + 1)) - 1

    # Step 3: Balance the tree through a series of left rotations
    # Perform initial compression
    compress_vine(dummy_root, node_count - perfect_tree_nodes)

    # Perform remaining compressions
    remaining_nodes = perfect_tree_nodes
    while remaining_nodes > 1:
        remaining_nodes //= 2
        compress_vine(dummy_root, remaining_nodes)

    return dummy_root.right
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d3_2" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage the Day-Stout-Warren (DSW) algorithm to balance the Binary Search
Tree (BST).
This approach consists of three main steps:

1. **Vine Creation:** Convert the BST into a "vine" (a right-skewed tree).
2. **Perfect Tree Size Calculation:** Determines the number of nodes needed for a perfect binary tree.
   A perfect binary tree is a binary tree in which all levels are filled except possibly for the lowest level,
   which is filled from left to right.
3. **Tree Balancing:** Perform a series of left rotations to balance the tree.

- **In-Place Transformation:** The DSW algorithm achieves balance through a series of tree rotations, without requiring
  extra space for node storage.
- **Guaranteed Balance:** It ensures a balanced tree with a height of $O(\log n)$.
- **Space Efficiency:** Unlike methods that require $O(n)$ auxiliary space, this approach uses only $O(1)$ extra space.

> **Key Insight:**
> By first creating a completely right-skewed tree (vine) and then performing a specific series of left
> rotations, we can achieve a balanced tree without needing to store all nodes in memory simultaneously.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d3_2" collapsible="true" default-state="expanded"}

1. **Helper Function Definitions:**
   ```python
   def right_rotate(parent: TreeNode, node: TreeNode) -> None:
       left_child = node.left
       node.left = left_child.right
       left_child.right = node
       parent.right = left_child
   ```
   The `right_rotate` function performs a right rotation on the given node:
   - It saves the left child of the node.
   - It sets the node's left child to be the right child of its former left child.
   - It makes the node the right child of its former left child.
   - It updates the parent to point to the new root of this subtree (the former left child).

   ```python
   def left_rotate(parent: TreeNode, node: TreeNode) -> None:
       right_child = node.right
       node.right = right_child.left
       right_child.left = node
       parent.right = right_child
   ```
   The `left_rotate` function performs a left rotation on the given node:
   - It saves the right child of the node.
   - It sets the node's right child to be the left child of its former right child.
   - It makes the node the left child of its former right child.
   - It updates the parent to point to the new root of this subtree (the former right child).

   ```python
   def compress_vine(vine_root: TreeNode, rotations: int) -> None:
       current_node = vine_root
       for _ in range(rotations):
           child = current_node.right
           left_rotate(current_node, child)
           current_node = current_node.right
   ```
   The `compress_vine` function performs a series of left rotations to balance part of the vine:
   - It starts from the `vine_root` and performs the specified number of `rotations`.
   - For each rotation, it performs a left rotation on the current node's right child.
   - After each rotation, it moves to the new right child to continue the process.

2. **Initialization:**
   ```python
   dummy_root = TreeNode()
   dummy_root.right = root
   current_node = dummy_root
   ```
   A dummy root is created to handle edge cases and simplify the vine creation process.
   The original root becomes the right child of this dummy node.

3. **Vine Creation (Step 1):**
   ```python
   while current_node.right:
       if current_node.right.left:
           right_rotate(current_node, current_node.right)
       else:
           current_node = current_node.right
   ```
   This loop converts the BST into a right-skewed tree (vine)
   by performing right rotations whenever a left child is encountered.

4. **Node Counting and Perfect Tree Size Calculation (Step 2):**
   ```python
   node_count = 0
   current_node = dummy_root.right
   while current_node:
       node_count += 1
       current_node = current_node.right

   perfect_tree_nodes = 2 ** math.floor(math.log2(node_count + 1)) - 1
   ```
   This section counts the total number of nodes
   and calculates the size of the largest perfect binary tree that can be formed with these nodes.
   The perfect tree size is determined by finding the largest power of 2 less than or equal to the node count.
   This is expressed as $2^{\lfloor \log_2(n + 1) \rfloor} - 1$.

5. **Tree Balancing (Step 3):**
   ```python
   compress_vine(dummy_root, node_count - perfect_tree_nodes)

   remaining_nodes = perfect_tree_nodes
   while remaining_nodes > 1:
       remaining_nodes //= 2
       compress_vine(dummy_root, remaining_nodes)
   ```
   The balancing process involves an initial compression to remove excess nodes,
   followed by a series of compressions that transform the vine into a balanced tree.
   Here we perform the initial compression and then iteratively reduce the number of remaining nodes by half,
   performing compressions at each step.

6. **Result Return:**
   ```python
   return dummy_root.right
   ```
   The function returns the right child of the dummy root, which is the root of the balanced BST.

---

#### Example {id="example_d3_2" collapsible="true" default-state="expanded"}

**Input:**

```python
root = TreeNode(4)
root.left = TreeNode(3)
root.left.left = TreeNode(2)
root.left.left.left = TreeNode(1)
```

A visual representation of the input BST:

![june26-2024-ap2-input.png](june26-2024-ap2-input.png)

**Step-by-Step Walkthrough:**

1. **Initialization:**
   - A dummy root is created and connected to the tree root.
   - The `current_node` is set to the dummy root.

2. **Step 1: Convert BST to vine (right-leaning linked list)**
   - We start with `current_node` as the dummy root.
   - We continue this process while `current_node.right` exists.
   - If `current_node.right.left` exists, we perform a right rotation.
   - Otherwise, we move `current_node` to `current_node.right`.

   - **Right Rotation 1:**
      - `current_node` is dummy, `current_node.right` is 4, and `current_node.right.left` is 3.
      - We perform a right rotation:
         1. Set `left_child = node.left` (left_child = 3)
         2. Set `node.left = left_child.right` (4.left = None)
         3. Set `left_child.right = node` (3.right = 4)
         4. Set `parent.right = left_child` (dummy.right = 3)
      - After rotation:
        ![june26-2024-ap2-right_rot_1_after.png](june26-2024-ap2-right_rot_1_after.png)

   - **Right Rotation 2:**
      - `current_node` is still dummy, `current_node.right` is now 3, and `current_node.right.left` is 2.
      - We perform another right rotation:
         1. Set `left_child = node.left` (left_child = 2)
         2. Set `node.left = left_child.right` (3.left = None)
         3. Set `left_child.right = node` (2.right = 3)
         4. Set `parent.right = left_child` (dummy.right = 2)
      - After rotation:
        ![june26-2024-ap2-right_rot_2_after.png](june26-2024-ap2-right_rot_2_after.png)

   - **Right Rotation 3:**
      - `current_node` is still dummy, `current_node.right` is now 2, and `current_node.right.left` is 1.
      - We perform the final right rotation:
         1. Set `left_child = node.left` (left_child = 1)
         2. Set `node.left = left_child.right` (2.left = None)
         3. Set `left_child.right = node` (1.right = 2)
         4. Set `parent.right = left_child` (dummy.right = 1)
      - After rotation:
        ![june26-2024-ap2-right_rot_2_after_1.png](june26-2024-ap2-right_rot_2_after_1.png)

   - Vine creation complete:
      - The BST is now a right-leaning linked list (vine)
      - Vine nodes: [1, 2, 3, 4]

3. **Step 2: Count nodes and calculate perfect tree size**
   - We traverse the vine to count the nodes:
      - Start with `current_node = dummy_root.right`
      - While `current_node` exists, increment `node_count` and move to `current_node.right`
   - Total node count: 4
   - Calculate perfect tree nodes: $2^{\lfloor \log_2(4 + 1) \rfloor} - 1 = 2^2 - 1 = 3$

4. **Step 3: Balance the tree through a series of left rotations**
   - We perform compressions to balance the tree.

   - **Initial Compression (1 rotation):**
      - Number of rotations = node_count - perfect_tree_nodes = 4 - 3 = 1
      - We perform 1 left rotation:
         1. Set `right_child = node.right` (right_child = 2)
         2. Set `node.right = right_child.left` (1.right = None)
         3. Set `right_child.left = node` (2.left = 1)
         4. Set `parent.right = right_child` (dummy.right = 2)
      - After compression (Left rotation):
        ![june26-2024-ap2-comp-1-after.png](june26-2024-ap2-comp-1-after.png)

   - **Remaining Compression (1 rotation):**
      - We calculate remaining_nodes = perfect_tree_nodes = 3
      - While remaining_nodes > 1, we divide it by 2: 3 // 2 = 1
      - We perform one more left rotation:
         1. Set `right_child = node.right` (right_child = 3)
         2. Set `node.right = right_child.left` (2.right = None)
         3. Set `right_child.left = node` (3.left = 2)
         4. Set `parent.right = right_child` (dummy.right = 3)
      - After compression (Left rotation):
        ![june26-2024-ap2-comp-2-after.png](june26-2024-ap2-comp-2-after.png)

5. **Compression Summary:**
   - Initial compressions: 1
   - Compression rounds: [1]

6. **Final Balanced Tree:**
   - The tree is now balanced, with a height difference of at most 1 between any two subtrees.

![june26-2024-ap2-comp-2-after.png](june26-2024-ap2-comp-2-after.png)

---

#### Complexity Analysis {id="complexity-analysis_d3_2" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(n)$, where $n$ is the number of nodes in the tree. This is because:
   1. Vine creation visits each node at most once: $O(n)$
   2. Node counting is a linear traversal: $O(n)$
   3. Tree balancing performs a constant number of operations per node: $O(n)$
   4. Despite multiple passes, each node is processed a constant number of times, resulting in linear time complexity.

**Space Complexity:**

- $O(1)$, which is constant space. This is because:
   1. The algorithm uses only a fixed number of additional variables (e.g., `dummy_root`, `current_node`)
   2. All operations are performed in-place, without requiring additional data structures that grow with input size
   3. The recursion depth (or iteration count) in helper functions is independent of the tree size

This space efficiency is a key advantage of the DSW algorithm,
especially for large trees where $O(n)$ extra space might be prohibitive.

---

## June 27 -> 1791. Find Center of Star Graph {collapsible="true" default-state="collapsed"}

There is an undirected **star** graph consisting of `n` nodes labeled from `1` to `n`.
A star graph is a graph where there is one **center** node and **exactly** `n - 1` edges that connect the center node
with every other node.

You are given a 2D integer array `edges` where each `edges[i] = [u_i, v_i]` indicates that there is an edge between the
nodes `u_i` and `v_i`.
Return the center of the given star graph.

**Example 1:**

- **Input:** edges = [[1,2],[2,3],[4,2]]
- **Output:** 2
- **Explanation:** As shown in the figure above, node 2 is connected to every other node, so 2 is the center.

**Example 2:**

- **Input:** edges = [[1,2],[5,1],[1,3],[1,4]]
- **Output:** 1

**Constraints:**

- `3 <= n <= 10^5`
- `edges.length == n - 1`
- `edges[i].length == 2`
- `1 <= u_i, v_i <= n`
- `u_i != vi`
- The given `edges` represent a valid star graph.

---

### Approach 1: Two-Edge Comparison {id="approach_d4_1" collapsible="true" default-state="expanded"}

```Python
def findCenter1(edges: List[List[int]]) -> int:
    """
    Determines the center node of a star graph given its edges.

    This function leverages the unique property of a star graph where the
    center node is connected to all other nodes. By comparing just two edges,
    we can identify the common node, which must be the center. This approach
    is highly efficient as it only needs to examine two edges regardless of
    the graph's size.

    The time complexity of this solution is O(1) because it performs a
    constant number of operations regardless of the input size. The space
    complexity is also O(1) as it only uses a fixed amount of additional
    memory.
    """
    reference_edge, comparison_edge = edges[0], edges[1]
    # The center node is the common node between the two edges
    return (reference_edge[0] if reference_edge[0] in comparison_edge
            else reference_edge[1])
```

{collapsible="true" default-state="expanded" collapsed-title="Two-Edge Comparison Code..."}

#### Understanding the Core Idea {id="core-idea_d4_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage the unique property of a star graph to efficiently identify the
center node.
In a star graph, the center node is connected to all other nodes, which means it appears on every edge.

- **Minimum Edge Requirement:** We only need to examine two edges to find the center node.
- **Common Node Principle:** The center node will be the only node that appears in both of these edges.

> **Key Insight:**
> By choosing any two edges from the graph, we can guarantee that the center node will be present in
> both, allowing us to identify it with minimal computation.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d4_1" collapsible="true" default-state="expanded"}

1. **Function Definition and Edge Selection:**
   ```python
   def findCenter1(edges: List[List[int]]) -> int:
       reference_edge, comparison_edge = edges[0], edges[1]
   ```
   The function takes a list of edges as input.
   It immediately selects the first two edges from this list, assigning them to `reference_edge` and `comparison_edge`.
   This selection is arbitrary but sufficient due to the star graph's properties.

2. **Center Node Identification:**
   ```python
   return (reference_edge[0] if reference_edge[0] in comparison_edge
            else reference_edge[1])
   ```
   This single line performs the core logic of the function:
   - It checks if the first node of the `reference_edge` is present in the `comparison_edge`.
   - If true, this node must be the center (as it's in both edges) and is returned.
   - If false, the second node of the `reference_edge` must be the center (since one of the two must be the center, and
     we've eliminated the first).

---

#### Example {id="example_d4_1" collapsible="true" default-state="expanded"}

**Input:**

```python
edges = [[1, 2], [5, 1], [1, 3], [1, 4]]
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
   - The function receives the `edges` list as input.
   - `reference_edge` is set to `[1, 2]` (the first edge in the list).
   - `comparison_edge` is set to `[5, 1]` (the second edge in the list).

2. **Center Node Identification:**
   - The function checks if the first node of `reference_edge` (1) is in `comparison_edge` [5, 1].
   - Condition: `1 in [5, 1]` evaluates to `True`.
   - Since the condition is true, the center node is identified as 1.

3. **Visual Aids:**
   A decision summary table is created:

   | Reference Edge | Comparison Edge | Condition   | Center Node |
   |----------------|-----------------|-------------|-------------|
   | [1, 2]         | [5, 1]          | 1 in [5, 1] | 1           |

4. **Result Calculation/Final Steps:**
   - The function determines that 1 is the center node.
   - This is correct because node 1 appears in all edges of the input, confirming it's connected to all other nodes.

---

#### Complexity Analysis {id="complexity-analysis_d4_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(1)$, where $n$ is the number of nodes in the graph.
  This is because the function performs a fixed number of operations regardless of the input size.
  It only accesses two edges and performs a single comparison.

**Space Complexity:**

- $O(1)$.
  The function uses only a constant amount of extra space to store the two selected edges and perform the
  comparison, regardless of the input size.

---

## June 28 -> 2285. Maximum Total Importance of Roads {collapsible="true" default-state="collapsed"}

You are given an integer `n` denoting the number of cities in a country. The cities are numbered from `0` to `n - 1`.

You are also given a 2D integer array `roads` where `roads[i] = [a_i, b_i]` denotes that there exists a 
**bidirectional** road connecting cities `a_i` and `b_i`.

You need to assign each city with an integer value from `1` to `n`, where each value can only be used **once**.
The **importance** of a road is then defined as the **sum** of the values of the two cities it connects.

Return *the **maximum total importance** of all roads possible after assigning the values optimally.*

**Example 1:**

![june28-2024-ex1.png](june28-2024-ex1.png)

- **Input:** n = 5, roads = [[0,1],[1,2],[2,3],[0,2],[1,3],[2,4]]
- **Output:** 43
- **Explanation:** The figure above shows the country and the assigned values of [2,4,5,3,1].
   - The road (0,1) has importance of 2 + 4 = 6.
   - The road (1,2) has importance of 4 + 5 = 9.
   - The road (2,3) has importance of 5 + 3 = 8.
   - The road (0,2) has importance of 2 + 5 = 7.
   - The road (1,3) has importance of 4 + 3 = 7.
   - The road (2,4) has importance of 5 + 1 = 6.
   - The total importance of all roads is 6 + 9 + 8 + 7 + 7 + 6 = 43.
   - It can be shown that we cannot get greater total importance than 43.

**Example 2:**

![june28-2024-ex2.png](june28-2024-ex2.png)

- **Input:** n = 5, roads = [[0,3],[2,4],[1,3]]
- **Output:** 20
- **Explanation:** The figure above shows the country and the assigned values of [4,3,2,5,1].
   - The road (0,3) has importance of 4 + 5 = 9.
   - The road (2,4) has importance of 2 + 1 = 3.
   - The road (1,3) has importance of 3 + 5 = 8.
   - The total importance of all roads is 9 + 3 + 8 = 20.
   - It can be shown that we cannot get greater total importance than 20.

**Constraints:**

- `2 <= n <= 5 * 10^4`
- `1 <= roads.length <= 5 * 10^4`
- `roads[i].length == 2`
- `0 <= a_i, b_i <= n - 1`
- `a_i != b_i`
- There are no duplicate roads.

---

### Approach 1: Greedy Assignment with Connection Count {id="approach_d5_1" collapsible="true" default-state="expanded"}

```Python
def maximumImportance1(n: int, roads: List[List[int]]) -> int:
    """
    Calculates the maximum total importance of all roads in a country with
    `n` cities and `roads` connecting them.

    This function uses a greedy approach to maximize the total importance.
    It first counts the number of connections for each city, then assigns
    values to cities based on their connection count in ascending order.
    This ensures that cities with more connections receive higher values,
    maximizing the overall importance. The algorithm works in three main
    steps, it first counts the connections for each city, then sorts the
    cities by their connection count, and finally assigns values and
    calculates the total importance.

    The time complexity is O(m + n log n), where `n` is the number of cities
    and `m` is the number of roads. This is due to first counting the
    connections (O(m)), then sorting the cities (O(n log n)), and finally
    calculating the total importance (O(n)). In the worst case, `m` could be
    O(n^2), but is constrained in this problem.
    The space complexity is O(n) for storing the `city_connections` list and
    O(n) for the sorting operation (Python's Timsort).
    """
    # Count the number of connections for each city
    city_connections = [0] * n
    for city1, city2 in roads:
        city_connections[city1] += 1
        city_connections[city2] += 1

    total_importance = 0
    city_value = 1

    # Assign values to cities based on their number of connections
    for connections in sorted(city_connections):
        total_importance += city_value * connections
        city_value += 1

    return total_importance
```

{collapsible="true" default-state="expanded" collapsed-title="Greedy Assignment with Connection Count Code..."}

#### Understanding the Core Idea {id="core-idea_d5_1" collapsible="true" default-state="expanded"}

The central concept of this solution is to leverage a greedy approach to maximize the total importance of roads.
The key insight is that assigning higher values to cities with more connections will result in the maximum total
importance.

- **Connection Count:** The solution starts by counting how many connections each city has.
- **Value Assignment:** Cities are then assigned values from 1 to n based on their connection count, with more connected
  cities receiving higher values.
- **Greedy Strategy:** This greedy strategy ensures that the cities contributing to more roads get higher values, thus
  maximizing the overall importance.

> **Key Insight:**
> The algorithm doesn't need to explicitly assign values to each city or calculate the importance of
> each road individually.
> Instead, it can calculate the total importance directly from the sorted connection counts and
> a running sum.
>
{style="note"}

---

#### Code Walkthrough {id="code-walkthrough_d5_1" collapsible="true" default-state="expanded"}

1. **Initialization and Connection Counting:**
   ```python
   city_connections = [0] * n
   for city1, city2 in roads:
       city_connections[city1] += 1
       city_connections[city2] += 1
   ```
   This step initializes a list `city_connections` to keep track of how many roads are connected to each city.
   It then iterates through the `roads` list, incrementing the count for both cities connected by each road.

2. **Initialization of Result Variables:**
   ```python
   total_importance = 0
   city_value = 1
   ```
   `total_importance` will store the final result, while `city_value` is used to assign increasing values to cities.

3. **Sorting and Importance Calculation:**
   ```python
   for connections in sorted(city_connections):
       total_importance += city_value * connections
       city_value += 1
   ```
   This is the core of the algorithm.
   It sorts the `city_connections` list, effectively ordering cities from least to most connected.
   Then, it iterates through this sorted list, calculating the contribution to the total importance for
   each city and incrementing the `city_value` for the next iteration.

4. **Result Return:**
   ```python
   return total_importance
   ```
   The final calculated `total_importance` is returned as the result.

---

#### Example {id="example_d5_1" collapsible="true" default-state="expanded"}

**Input:**
```python
n = 5
roads = [[0, 1], [1, 2], [2, 3], [0, 2], [1, 3], [2, 4]]
```

**Step-by-Step Walkthrough:**

1. **Initialization:**
   - We start with `n = 5` cities and a list of `roads` connecting them.
   - Initialize `city_connections = [0, 0, 0, 0, 0]`, a list to count connections for each city.

2. **Counting Connections:**
   - Iterate through each road in `roads`:
      - **Road 1:** 0 <-> 1 → Update: `city_connections = [1, 1, 0, 0, 0]`
      - **Road 2:** 1 <-> 2 → Update: `city_connections = [1, 2, 1, 0, 0]`
      - **Road 3:** 2 <-> 3 → Update: `city_connections = [1, 2, 2, 1, 0]`
      - **Road 4:** 0 <-> 2 → Update: `city_connections = [2, 2, 3, 1, 0]`
      - **Road 5:** 1 <-> 3 → Update: `city_connections = [2, 3, 3, 2, 0]`
      - **Road 6:** 2 <-> 4 → Update: `city_connections = [2, 3, 4, 2, 1]`

3. **Sorting Connections:**
   - Sort `city_connections` in ascending order: `[1, 2, 2, 3, 4]`
   - Here is how the cities are sorted based on their connection counts:

   | City # | Connections |
   |--------|-------------|
   | 4      | 1           |
   | 0/3    | 2           |
   | 3/0    | 2           |
   | 1      | 3           |
   | 2      | 4           |

4. **Calculating Importance:**
   - Initialize `total_importance = 0` and `city_value = 1`
   - Iterate through sorted connections:
      - **Iteration 1:** 
        - We start with city 4 (1 connection) and assign it value 1.
        - 1 * 1 = 1, `total_importance = 1`, incremented city_value for next iteration: 2
      - **Iteration 2:** 
        - The next city is 0/3 (2 connections) and assigned value 2.
        - 2 * 2 = 4, `total_importance = 5` (1 + 4), incremented city_value: 3
      - **Iteration 3:**
        - The next city is 3/0 (2 connections) and assigned value 3.
        - 3 * 2 = 6, `total_importance = 11` (5 + 6), incremented city_value: 4
      - **Iteration 4:**
        - The next city is 1 (3 connections) and assigned value 4.
        - 4 * 3 = 12, `total_importance = 23` (11 + 12), incremented city_value: 5
      - **Iteration 5:**
        - The final city is 2 (4 connections) and assigned value 5.
        - 5 * 4 = 20, `total_importance = 43` (23 + 20)

5. **Visual Aid:**

   Iteration Summary Table:
   
   | City # | Connections | Assigned Value | Importance Contribution | Total Importance |
   |--------|-------------|----------------|-------------------------|------------------|
   | 4      | 1           | 1              | 1                       | 1                |
   | 0/3    | 2           | 2              | 4                       | 5                |
   | 3/0    | 2           | 3              | 6                       | 11               |
   | 1      | 3           | 4              | 12                      | 23               |
   | 2      | 4           | 5              | 20                      | 43               |

6. **Result Calculation:**
   - The final `total_importance` is 43, which is the sum of all importance contributions.
   - This value represents the maximum total importance of all roads after optimally assigning values to cities.

---

#### Complexity Analysis {id="complexity-analysis_d5_1" collapsible="true" default-state="expanded"}

**Time Complexity:**

- $O(m + n \log n)$, where $n$ is the number of cities and $m$ is the number of roads.
   - Counting connections: $O(m)$
   - Sorting the connection counts: $O(n \log n)$
   - Final calculation loop: $O(n)$

  The overall complexity is dominated by the sorting step, hence $O(m + n \log n)$.

**Space Complexity:**

- $O(n)$, where $n$ is the number of cities.
   - The `city_connections` list uses $O(n)$ space.
   - The sorting operation in Python (Timsort) uses $O(n)$ space in the worst case.
   - All other variables use constant space.

---

## June 29 -> 6. Problem Name {collapsible="true" default-state="collapsed"}

[Problem Statement]

---

### Approach 1: Approach Name {id="approach_d6_1" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d6_1" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d6_1" collapsible="true" default-state="expanded"}

...

---

### Approach 2: Approach Name {id="approach_d6_2" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d6_2" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d6_2" collapsible="true" default-state="expanded"}

...

---

## June 30 -> 7. Problem Name {collapsible="true" default-state="collapsed"}

[Problem Statement]

---

### Approach 1: Approach Name {id="approach_d7_1" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d7_1" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d7_1" collapsible="true" default-state="expanded"}

...

---

### Approach 2: Approach Name {id="approach_d7_2" collapsible="true" default-state="expanded"}

```Python
# Code
```

{collapsible="true" default-state="expanded" collapsed-title="Approach Name Code..."}

#### Understanding the Core Idea {id="core-idea_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Code Walkthrough {id="code-walkthrough_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Example {id="example_d7_2" collapsible="true" default-state="expanded"}

...

---

#### Complexity Analysis {id="complexity-analysis_d7_2" collapsible="true" default-state="expanded"}

...

---
